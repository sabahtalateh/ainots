# Введение в Data Science

[Презентация](https://docs.yandex.ru/docs/view?url=ya-disk-public%3A%2F%2F3xs3DkSMawrEZ6kRQrOeB5EtCaoB%2FjzsZZ7D%2BxwzSGFAfOGHvznjItrO6uk9i8T9q%2FJ6bpmRyOJonT3VoXnDag%3D%3D%3A%2FDS_Fundamentals_v6_2025.pptx&name=DS_Fundamentals_v6_2025.pptx)

[ГОСТ Р 59277-2020](./gost-r-59277-2020.pdf)

## [Модуль 1] Область применения больших данных. Постановка задачи

### Информация общего характера

- Для построения нейронной сети используется **метод наименьших квадратов** (изобретённый математиками в XVII веке). В настоящее время просто появились достаточные вычислительные мощности для такого построения, этим объясняется хайп вокруг данной темы (генерируется больше данных, для обработки которых нужны большие мощности, которые могут генерировать и обрабатывать ещё больше данных, в частности большие количества переборов, которые нужны для обучения нейросетей)
- Нейросеть это граф (очень упрощённый). (см. "Задачу о Кенигсбергских мостах")
- Современные "Новые модели" сетей это очень частные модификации общих алгоритмов, заточнные под конкретные задачи

### История

- XVII в. Сэр Исаак Ньютон анализ типа зависимости между двумя переменными (метод Ньютона)
- 1920-е, сэр Фишер — основы статистики
- 1960-е гг. Комитет по данным для науки и техники (CODATA)
- 1974 г. Первое использование термина Data Science (Питер Наур)
- 2002 г. Начат выпуск Data Science Journal
- 2011 — н.в. — взлет популярности, массовые конференции,
открытие учебных программ в ведущих учебных заведениях.
- 2023 — массовое применение генеративных (GPT) сетей

### Основные понятия и термины

#### Искуственный интеллект

Искуственный интеллект, ИИ (англ. Artificial intelligence, AI) это *(Определение крайне размытое)*:

1. Наука и технология создания интеллектуальных машин, особенно интеллектуальных компьютерных программ.
2. Свойство интеллектуальных систем выполнять творческие функции, которые традиционно считаются прерогативой человека.

#### Большие данные
**Cовокупность подходов, инструментов и методов** (а не только сами данные) обработки структурированных и неструктурированных данных огромных объёмов и значительного многообразия для получения воспринимаемых человеком результатов, эффективных в условиях непрерывного прироста, распределения по многочисленным узлам вычислительной сети.

#### Машинное обучение (англ. Machine Learning)
Класс методов искусственного интеллекта, характерной чертой которых является не прямое решение задачи, а обучение в процессе применения решению множества сходных задач. Для построения таких методов используются средства математической статистики, численных методов, методов оптимизации, теории вероятностей, теории графов, различные техники работы с данными в цифровой форме.

### Классификация систем искусственного интеллекта

Из [ГОСТа Р 59277-2020](./gost-r-59277-2020.pdf).

<img src="./images/aiclasses.png">

### Скрытые знания

Обучение нейросетей помогает (в том числе) выявить скрытые (ранее неизвестные) зависимости.

- Ранее неизвестные — то есть такие знания, которые должны быть новыми (а не подтверждающими какие-то ранее
полученные сведения).
- Нетривиальные, неочевидные — то есть такие, которые нельзя просто увидеть при непосредственном визуальном анализе данных.
- Практически полезные — то есть такие знания, которые
представляют ценность для исследователя или потребителя (современные AI модели могут генерировать галлюцинации).
- Доступные для интерпретации — знания, которые легко
представить в наглядной для пользователя форме и легко
объяснить в терминах предметной области (невозможно/сложно объяснить почему AI модель выдаёт определённый ответ).

## [Модуль 2] Сбор и подготовка исходных данных. Методика CRISP-DM

### Знание из данных (KDD)

KDD (Knowledge Discovery in Databases) — извлечение знаний из
баз данных это процесс поиска полезных знаний в «сырых данных».

KDD включает в себя вопросы подготовки данных, выбора
информативных признаков, очистки данных, применения
методов Data Mining (DM), постобработки данных и
интерпретации полученных результатов.

### Модель DIKW (Data - Information - Knowledge - Wisdom)

DIKW — это иерархическая модель, описывающая переход от данных к мудрости через информацию и знания. Каждый уровень пирамиды добавляет ценность предыдущему

<img src="./images/dikw.png">

#### 1. Data (Данные) — базовый уровень

- **Определение**: Необработанные факты, символы, цифры без контекста
- **Характеристики**: 
  - Неструктурированные или структурированные наблюдения
  - Не имеют значения сами по себе
  - Количественные или качественные показатели
- **Примеры**: температура 25°C, число 42, набор пикселей изображения, строки в базе данных
- **В Data Science**: логи, сенсорные показания, транзакции

#### 2. Information (Информация) — данные в контексте

- **Определение**: Обработанные, организованные данные, имеющие контекст и значение. Связанные друг с другом данные
- **Характеристики**:
  - Данные с добавленным контекстом (кто, что, где, когда)
  - Отвечает на вопросы: "Что произошло?"
  - Результат агрегации, фильтрации, анализа данных
- **Примеры**: "Температура повысилась на 5°C за час", "Продажи выросли на 20%"
- **В Data Science**: визуализации, отчеты, дашборды, статистические сводки

#### 3. Knowledge (Знания) — информация с пониманием

- **Определение**: Информация с добавленным пониманием связей, паттернов и закономерностей
- **Характеристики**:
  - Отвечает на вопрос "Как?" и "Почему?"
  - Включает опыт, контекст и интерпретацию
  - Позволяет делать прогнозы
- **Примеры**: "Повышение температуры вызывает рост продаж мороженого", понимание корреляций и причинно-следственных связей
- **В Data Science**: модели машинного обучения, правила, паттерны, выявленные зависимости

#### 4. Wisdom (Мудрость) — высший уровень

- **Определение**: Способность принимать оптимальные решения на основе знаний с учетом этики, ценностей и последствий
- **Характеристики**:
  - Отвечает на вопрос "Что делать?" и "Зачем?"
  - Включает суждения, оценку и предвидение
  - Учитывает долгосрочные последствия
- **Примеры**: "Стоит ли увеличивать производство мороженого, учитывая сезонность и экологические факторы?"
- **В Data Science**: стратегические решения на основе аналитики, этические соображения при использовании AI

---

**Ключевая идея**: В Data Science мы собираем **данные**, преобразуем их в **информацию** через анализ, извлекаем **знания** с помощью ML/AI моделей, и применяем **мудрость** для принятия обоснованных бизнес-решений.

Эта иерархия соответствует процессу KDD (Knowledge Discovery in Databases), описанному выше.

### Инструменты обработки данных

- Excel
- IBM SPSS, GNU PSPP
- Tableau — инструмент визуализации аналитики, интерпретируемый язык для статистической обработки данных и работы с графикой. Использует режим командной строки
- Python — высокоуровневый язык программирования, поддерживающий  структурное, объектно-ориентированное, функциональное, императивное и аспектно-ориентированное программирование
- Octave — система для математических вычислений, использующая совместимый с MATLAB язык высокого уровня
- NoSQL базы данных, в которых делается попытка решить проблемы масштабируемости и доступности за счёт атомарности (англ. atomicity) и согласованности данных:
    - Хранилища «ключ-значение», документоориентированные БД (Cache, MongoSQL), разреженные (bigtable OLAP, Hadoop) БД, графовые БД.
- ИИ ассистенты
- ИИ агенты

### Методология CRISP-DM

**CRISP-DM** (Cross-Industry Standard Process for Data Mining) — стандартная отраслевая методология для проектов по анализу данных и машинному обучению, разработанная в 1996 году консорциумом европейских компаний.

#### Что это такое

CRISP-DM — это итеративный циклический процесс, описывающий жизненный цикл проекта Data Science от начала до конца. Методология не привязана к конкретным инструментам или отраслям и применима к любым проектам анализа данных.

#### Зачем нужен CRISP-DM

- **Структурированный подход**: Предоставляет четкий план действий для организации и выполнения Data Science проектов
- **Снижение рисков**: Помогает избежать типичных ошибок благодаря проверенной последовательности этапов
- **Коммуникация**: Обеспечивает общий язык между бизнесом, аналитиками и техническими специалистами
- **Итеративность**: Позволяет возвращаться к предыдущим этапам при необходимости улучшения результатов
- **Масштабируемость**: Применим как к небольшим, так и к крупным проектам

#### Шесть этапов CRISP-DM

<img src="./images/crispdm.jpg">

**1. Business Understanding (Понимание бизнеса)**
- Определение бизнес-целей
- Оценка ситуации и ресурсов
- Определени целей аналитики
- Подготовка плана проекта

**2. Data Understanding (Понимание данных)**
- Сбор данных
- Описание данных
- Изучение данных (EDA)
- Проверка качества данных

**3. Data Preparation (Подготовка данных)**
- Выборка данных
- Очистка данных. Трансформация и нормализация
- Генерация данных
- Форматирование данных

**4. Modeling (Моделирование)**
- Выбор методов и алгоритмов моделирования
- Подготовка плана тестирования
- Обучение моделей
- Оценка качества моделей

**5. Evaluation (Оценка)**
- Оценка результатов
- Оценка процесса
- Определение следующих шагов

**6. Deployment (Развертывание)**
- Внедрение
- Планирование мониторинга и поддержки
- Подготовка отчёта
- Ревью проекта

#### Циклический характер

CRISP-DM — это не линейный процесс. На любом этапе может потребоваться вернуться к предыдущим шагам:
- Низкое качество данных → возврат к сбору данных
- Плохие результаты моделирования → возврат к подготовке данных
- Изменение бизнес-требований → возврат к пониманию бизнеса

**Вывод**: CRISP-DM обеспечивает систематический и воспроизводимый подход к реализации Data Science проектов, увеличивая вероятность их успешного завершения.

### Обработка данных

#### Подготовка исходного набора данных
Этот этап заключается в создании набора данных, в том числе консолидации сведений из различных источников, определение выборки, которая и будет в последствии анализироваться.

#### Предобработка и очистка данных
Данные могут содержать пропуски, шумы, аномальные значения, могут быть избыточны, недостаточны и т.д. В некоторых задачах требуется дополнить данные некоторой априорной информацией. Данные должны быть качественны и корректны с точки зрения используемого метода анализа.

#### Трансформация данных
Для различных методов анализа требуются данные, подготовленные в специальном виде. Например, некоторые методы анализа в качестве входных полей могут использовать только числовые данные, а некоторые, наоборот,только категориальные.

#### Data Mining
На этом шаге применяются различные алгоритмы для поиска зависимостей, новых знаний, или говорят, что строятся модели. Выделяют два больших класса моделей — описательные и предсказательные. Для этого используются как классические статистические методы, так и самообучающиеся алгоритмы и машинное обучение (нейронные сети, деревья решений и др.).

#### Постобработка данных
Тестирование, интерпретация результатов и практическое применение полученных знаний в выбранной прикладной области.

### Очистка и подготовка данных

- Удалить дублирующие записи (могут возникнуть вследствие использования различных источников первичных данных)
- Заполнить пропущенные значение (например, с помощью средних значений или ожидаемых (математическое ожидание))
- Преобразовать данные к сравнимым значения (например, вместо количество покупателей и сумма покупок использовать средний чек)
- Сгруппировать значения по «корзинам». Например, уровень дохода: низкий, средний, высокий
- Свести данные к единым временным интервалам. Обычно наиболее длительному из имеющихся
- Удалить случайные значения (например, данные о случайно крупной покупке)
- Проверить данные на соответствие выборки реальным распределениям по типам (например, в выборке данные 80% мужчин и 20% женщин, что нерепрезентативно для популяции)

### «Добыча» данных. Data mining

#### Ассоциация
Выявление зависимостей между связанными событиями, указывающих, что из события X следует событие Y. Такие правила называются ассоциативными.

#### Регрессия
Установление функциональной зависимости между входными и непрерывными выходными переменными.

#### Классификация
Установление функциональной зависимости между входными и дискретными выходными переменными.

#### Кластеризация
Группировка объектов (наблюдений, событий) на основе данных (свойств), описывающих сущность объектов. Чем больше похожи объекты внутри кластера и чем больше отличий между кластерами, тем точнее кластеризация.

### Озера данных (Data Lakes)

Это метод хранения данных системой или репозиторием в натуральном (RAW) формате, который предполагает одновременное хранение данных в различных схемах и форматах. Обычно используется blob-объект (binary large object) или файл. Идея озера данных в том чтобы иметь логически определенное, единое хранилище всех данных в организации (enterprise data) начиная от сырых, необработанных исходных данных (RAW data) до предварительно обработанных (transformed) данных, которые используются для различных задач: отчеты, визуализация, аналитика и машинное обучение.

Data lake включает структурированные данные из реляционных баз данных (строки и колонки), полуструктурированные данные (CSV, лог файлы, XML, JSON), неструктурированные данные (почтовые сообщения, документы, pdf) и даже бинарные данные (видео, аудио, графические файлы).

#### Требования к озёрам данных

- **Масштабируемость** — хранение петабайт данных, горизонтальное масштабирование (HDFS, S3, Azure Data Lake)
- **Гибкость** — Schema-on-Read, поддержка всех форматов данных без предварительной схемы
- **Безопасность** — шифрование, RBAC, аудит, соответствие законодательству (GDPR, ФЗ-152)
- **Метаданные** — каталогизация, Data Lineage, автоматическое индексирование
- **Качество данных** — валидация, мониторинг, версионирование
- **Производительность** — batch/streaming загрузка, параллельная обработка
- **Интеграция** — API, ETL/ELT, поддержка SQL
- **Жизненный цикл** — политики хранения, архивирование, оптимизация затрат

**Отличия от Data Warehouse:** Data Lake использует Schema-on-Read (схема при чтении), хранит все форматы данных в сыром виде с низкой стоимостью, подходит для Data Scientists. Data Warehouse использует Schema-on-Write, хранит структурированные обработанные данные, подходит для бизнес-аналитиков.

#### Состав озёр данных

Озеро данных — многослойная архитектура из следующих элементов:

**1. Слой хранения данных (Storage Layer)**
- **Raw Zone** — сырые данные в исходном формате
- **Processed Zone** — очищенные и трансформированные данные
- **Curated Zone** — готовые для анализа данные, агрегаты
- Технологии: HDFS, Amazon S3, Azure Blob Storage, Google Cloud Storage

**2. Слой приёма данных (Ingestion Layer)**
- Batch загрузка — периодическая загрузка больших объёмов
- Streaming — потоковая загрузка в реальном времени
- Технологии: Apache Kafka, Apache Flume, Spark, AWS Glue, Kinesis

**3. Слой метаданных (Metadata & Catalog Layer)**
- Каталог данных с описанием схем и структур
- Data Lineage — отслеживание происхождения и трансформаций данных
- Технологии: Apache Atlas, AWS Glue Catalog, Azure Purview

**4. Слой обработки (Processing & Analytics Layer)**
- Batch обработка — пакетная обработка больших объёмов (Apache Spark, MapReduce, Hive)
- Stream обработка — обработка потоковых данных (Apache Flink, Spark Streaming)
- SQL движки — запросы к данным (Presto, Athena, Apache Drill)
- ML фреймворки — машинное обучение (TensorFlow, PyTorch, MLlib)

**5. Слой безопасности (Governance & Security Layer)**
- Управление доступом (RBAC/ABAC), шифрование, аудит, compliance
- Технологии: Apache Ranger, Apache Knox

**6. Слой потребления (Consumption Layer)**
- BI инструменты (Tableau, Power BI), Notebooks (Jupyter, Zeppelin), API для приложений

**7. Слой оркестрации (Orchestration Layer)**
- Управление workflow, планировщики задач
- Технологии: Apache Airflow, Luigi, Oozie

**Зоны по температуре данных:**
- **Hot Zone** — часто используемые данные, быстрый доступ, высокая стоимость
- **Warm Zone** — периодически используемые данные
- **Cold Zone** — архивные данные, редкий доступ (Amazon Glacier, Azure Archive)

## [Модуль 3] Задачи численного прогнозирования. Понятие машинного обучения. Корреляция. Регрессионный анализ

До **70%** задач из Data Science решается методам статистики.

### Описательная статистика

Цель описательной (дескриптивной) статистики это обработка эмпирических данных, их систематизация, наглядное представление, а также их количественное описание посредством основных статистических показателей.

#### Медиана. Мода. Среднее

<img src="./images/median-mode-mean.png">

- **Среднее арифметическое (СА)** — отношение суммы значений к их количеству. Использовать среднее это плохая идея, так как оно неустойчиво к выбросам
- **Медиана** — значение, которое делит набор данных на 2 равные части
- **Мода** — величина признака (значение), которая чаще всего встречается в данной совокупности

##### Пример: распределение зарплат

**Условие:** 10 человек получили деньги. 9 человек получили по 1 рублю, 1 человек получил 100 рублей.

**Данные:** 1, 1, 1, 1, 1, 1, 1, 1, 1, 100

**Среднее арифметическое:**
- (1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 100) / 10 = 109 / 10 = **10.9 рубля**
- Интерпретация: "В среднем каждый получил 10.9 рубля" — вводит в заблуждение! 9 из 10 человек получили всего 1 рубль

**Медиана:**
- Упорядоченные данные: 1, 1, 1, 1, 1 | 1, 1, 1, 1, 100
- Среднее между 5-м и 6-м значением: (1 + 1) / 2 = **1 рубль**
- Интерпретация: "Половина людей получили не более 1 рубля" — точно отражает реальность

**Мода:**
- Значение 1 встречается 9 раз, значение 100 встречается 1 раз
- Результат: **1 рубль**
- Интерпретация: "Большинство людей (90%) получили 1 рубль"

**Вывод:** При наличии выбросов (экстремальных значений) медиана и мода показывают типичную ситуацию лучше, чем среднее. Если в новостях скажут "средняя зарплата в компании 10.9 рублей", это правда, но 90% сотрудников получают всего 1 рубль.

#### Математическое ожидание

**Математическое ожидание (Expected Value, E(X))** — это среднее значение случайной величины при большом числе испытаний. Показывает, какое значение можно ожидать "в среднем" при многократном повторении случайного эксперимента.

**Формула для дискретной случайной величины:**

$$
E(X) = \sum_{i=1}^{n} x_i \cdot p_i
$$

где:
- $x_i$ — возможные значения случайной величины
- $p_i$ — вероятность каждого значения
- $n$ — количество возможных исходов

##### Пример: бросок игральной кости

**Условие:** Бросаем честную шестигранную игральную кость один раз. Какое математическое ожидание выпавшего числа?

**Исходные данные:**
- Возможные значения: 1, 2, 3, 4, 5, 6
- Вероятность каждого значения: $p = \frac{1}{6}$ (кость честная)

**Расчёт:**

$$
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
$$

$$
E(X) = \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \frac{21}{6} = 3.5
$$

**Результат:** $E(X) = 3.5$

**Интерпретация:** 
- При многократных бросках кости среднее значение будет стремиться к 3.5
- Хотя на кости нет грани с числом 3.5, это теоретическое среднее для большого числа бросков
- Если бросить кость 1000 раз и вычислить среднее арифметическое выпавших чисел, оно будет близко к 3.5

**Практическое применение:**
- **В играх:** расчёт средней выгоды от игры (например, казино)
- **В инвестициях:** ожидаемая доходность портфеля
- **В ML:** ожидаемая ошибка модели
- **В бизнесе:** средний доход от клиента, средний чек

**Свойства математического ожидания:**
- $E(c) = c$ (константа равна сама себе)
- $E(aX + b) = aE(X) + b$ (линейность)
- $E(X + Y) = E(X) + E(Y)$ (сумма ожиданий равна ожиданию суммы)

#### Дисперсия и среднеквадратичное отклонение

**Дисперсия (Variance, $\sigma^2$ или D(X))** — это мера разброса (рассеяния) значений случайной величины относительно её математического ожидания. Показывает, насколько сильно значения отклоняются от среднего.

**Формула дисперсии для случайной величины:**

$$
\text{D}(X) = E[(X - E(X))^2] = E(X^2) - (E(X))^2
$$

**Среднеквадратичное отклонение (Standard Deviation, $\sigma$ или SD)** — это квадратный корень из дисперсии. Измеряется в тех же единицах, что и исходные данные, поэтому более интерпретируемо.

**Формула:**

$$
\sigma = \sqrt{\text{D}(X)}
$$

##### Пример: оценки студентов

**Условие:** Два студента сдали по 5 экзаменов. Найти дисперсию и СКО для каждого.

**Данные:**
- Студент А: 3, 3, 3, 3, 3 (стабильные оценки)
- Студент Б: 1, 2, 3, 4, 5 (разброс оценок)

**Расчёт для студента А:**

Среднее: $\bar{x}_A = \frac{3 + 3 + 3 + 3 + 3}{5} = 3$

Дисперсия:

$$
\sigma_A^2 = \frac{(3-3)^2 + (3-3)^2 + (3-3)^2 + (3-3)^2 + (3-3)^2}{5} = \frac{0}{5} = 0
$$

СКО: $\sigma_A = \sqrt{0} = 0$

**Расчёт для студента Б:**

Среднее: $\bar{x}_B = \frac{1 + 2 + 3 + 4 + 5}{5} = 3$

Дисперсия:

$$
\sigma_B^2 = \frac{(1-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (5-3)^2}{5} = \frac{4 + 1 + 0 + 1 + 4}{5} = \frac{10}{5} = 2
$$

СКО: $\sigma_B = \sqrt{2} \approx 1.41$

**Интерпретация:**
- У обоих студентов средний балл = 3
- У студента А разброс = 0 (всегда одинаковые оценки, стабильность)
- У студента Б разброс = 1.41 (оценки варьируются, нестабильность)

**Практическое применение:**

- **В финансах:** измерение риска (волатильность акций)
- **В производстве:** контроль качества (отклонение от стандарта)
- **В ML:** оценка стабильности модели, нормализация данных
- **В бизнесе:** анализ предсказуемости метрик

**Свойства дисперсии:**
- D(c) = 0 (дисперсия константы равна нулю)
- D(aX + b) = a² · D(X) (константа b не влияет)
- Дисперсия всегда неотрицательна: D(X) ≥ 0

**Правило "трёх сигм" (для нормального распределения):**
- ~68% значений лежат в пределах $E(X) \pm \sigma$
- ~95% значений лежат в пределах $E(X) \pm 2\sigma$
- ~99.7% значений лежат в пределах $E(X) \pm 3\sigma$

#### Стандартная ошибка среднего

**Стандартная ошибка среднего (Standard Error of the Mean, SE или SEM)** — это оценка стандартного отклонения распределения выборочных средних. Показывает, насколько выборочное среднее может отличаться от истинного среднего в генеральной совокупности.

**Формула:**

$$
SE = \frac{\sigma}{\sqrt{n}}
$$

где:
- $\sigma$ — стандартное отклонение генеральной совокупности (или выборочное СКО)
- $n$ — размер выборки

**Ключевое отличие:**
- **Стандартное отклонение ($\sigma$)** — измеряет разброс отдельных значений
- **Стандартная ошибка (SE)** — измеряет точность оценки среднего значения

##### Пример: измерение роста студентов

**Условие:** Проведено два исследования роста студентов университета. Стандартное отклонение роста = 10 см.

**Исследование 1:** Выборка из 25 студентов

$$
SE_1 = \frac{10}{\sqrt{25}} = \frac{10}{5} = 2 \text{ см}
$$

**Исследование 2:** Выборка из 100 студентов

$$
SE_2 = \frac{10}{\sqrt{100}} = \frac{10}{10} = 1 \text{ см}
$$

**Интерпретация:**
- В обоих случаях разброс роста отдельных студентов = 10 см
- Но точность оценки среднего роста разная:
  - С выборкой 25 человек: среднее может отличаться от истинного на ~2 см
  - С выборкой 100 человек: среднее может отличаться от истинного на ~1 см
- **Вывод:** Чем больше выборка, тем точнее оценка среднего (SE уменьшается)

**Практическое применение:**

- **В исследованиях:** оценка точности результатов эксперимента
- **Доверительные интервалы:** построение интервалов для среднего (обычно $\bar{x} \pm 2 \cdot SE$)
- **A/B тестирование:** определение статистической значимости различий
- **Опросы:** оценка погрешности среднего мнения в выборке

**Важное свойство**  
Стандартная ошибка уменьшается пропорционально корню из размера выборки. Чтобы уменьшить SE в 2 раза, нужно увеличить выборку в 4 раза.

### Ассоциативная статистика. Корреляция

**Корреляция или корреляционная зависимость** — статистическая взаимосвязь двух или более случайных величин (либо величин, которые можно с некоторой допустимой степенью точности считать таковыми). При этом изменения значений одной или нескольких из этих величин сопутствуют систематическому изменению значений другой или других величин.

**Математической мерой корреляции** двух случайных величин служит коэффициент корреляции **R** либо корреляционное отношение **F**.

#### Коэффициент корреляции Пирсона

**Коэффициент корреляции Пирсона (Pearson correlation coefficient, r)** — мера линейной зависимости между двумя переменными X и Y. Принимает значения от -1 до +1.

**Формула:**

$$
r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2} \cdot \sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}
$$

Альтернативная форма записи:

$$
r = \frac{n\sum x_iy_i - \sum x_i \sum y_i}{\sqrt{n\sum x_i^2 - (\sum x_i)^2} \cdot \sqrt{n\sum y_i^2 - (\sum y_i)^2}}
$$

где:
- $x_i, y_i$ — значения переменных X и Y
- $\bar{x}, \bar{y}$ — средние значения переменных X и Y
- $n$ — количество наблюдений

**Интерпретация значений:**
- $r = 0$ — отсутствие линейной корреляции
- $r > 0.5$ — положительная корреляция
- $r < -0.5$ — отрицательная корреляция
- $r = 1$ — полная положительная линейная корреляция
- $r = -1$ — полная отрицательная линейная корреляция

**Важно:** Коэффициент Пирсона измеряет только линейную зависимость. Если r = 0, это не означает отсутствие зависимости вообще — может существовать нелинейная связь.

### Сравнительная статистика

Помогает ответить на такие вопросы
- Это тенденция или случайность?
- Каков риск принятия гипотезы?
- Выборки должны быть независимыми

**Например:** продажи товара А ведут к увеличению продаж
товара В

#### T-тест на одной и двух выборках

**T-тест (Student's t-test)** — статистический критерий для проверки гипотез о средних значениях. Используется для определения, значимо ли отличается среднее значение выборки от известного значения или средние двух выборок друг от друга.

##### T-тест на одной выборке (One-Sample t-test)

**Назначение:** Проверяет, отличается ли среднее значение выборки от известного (гипотетического) значения генеральной совокупности.

**Формула:**

$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}
$$

где:
- $\bar{x}$ — среднее значение выборки
- $\mu_0$ — гипотетическое среднее значение генеральной совокупности (с которым сравниваем)
- $s$ — стандартное отклонение выборки
- $n$ — размер выборки
- $s / \sqrt{n}$ — стандартная ошибка среднего (SE)

##### T-тест для двух независимых выборок (Two-Sample t-test)

**Назначение:** Проверяет, отличаются ли средние значения двух независимых выборок друг от друга.

**Формула (для выборок с неравными дисперсиями — тест Уэлча):**

$$
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

где:
- $\bar{x}_1$ — среднее арифметическое значение **первой выборки** (например, средний балл группы А)
- $\bar{x}_2$ — среднее арифметическое значение **второй выборки** (например, средний балл группы Б)
- $s_1$ — стандартное отклонение **первой выборки** (мера разброса данных в группе А)
- $s_2$ — стандартное отклонение **второй выборки** (мера разброса данных в группе Б)
- $n_1$ — количество наблюдений (размер) **первой выборки** (сколько человек в группе А)
- $n_2$ — количество наблюдений (размер) **второй выборки** (сколько человек в группе Б)


**P-значение** (англ. P-value)— вероятность получить для данной вероятностной модели распределения значений случайной величины такое же или более экстремальное значение статистики (среднего арифметического, медианы и др.), по сравнению с ранее наблюдаемым, при условии, что нулевая гипотеза верна

Если p(t) меньше заданного уровня значимости, то нулевая
гипотеза отвергается в пользу альтернативной. В противном
случае она не отвергается.

<img src="./images/ttest.png">

Критерий Стьюдента (Т-тест) оценивает вероятность попадания значения из выборки в область принятия. Если оценка попадает в область отклонения, то мы вправе отклонить гипотезу.

Обычно принимают, что вероятность попадания в область отклонения
не должна превышать 5%.

### Основы машинного обучения

(от англ. – machine learning) – алгоритмы, позволяющие компьютеру делать выводы на основании данных, не следуя определенным правилам.

#### Некоторые области применения

- Распознавание речи
- Распознавание жестов
- Распознавание рукописного ввода
- Распознавание образов
- Техническая диагностика
- Медицинская диагностика
- Прогнозирование временных рядов
- Биоинформатика
- Обнаружение мошенничества
- Обнаружение спама
- Категоризация документов
- Биржевой технический анализ
- Финансовый надзор
- Кредитный скоринг
- Предсказание ухода клиентов

#### Обучение «с учителем». Supervised learning

Один из способов машинного обучения, в ходе которого испытуемая система принудительно обучается с помощью примеров «стимул-реакция». Между входами и эталонными выходами (стимул-реакция) может существовать некоторая зависимость, но она неизвестна. Известна только конечная совокупность прецедентов — пар «стимул-реакция», называемая обучающей выборкой.

<img src="./images/supervised.png">

#### Обучение «без учителя». Unsupervised learning

Обучение без учителя (самообучение, спонтанное обучение) — один из способов машинного обучения, при котором испытуемая система спонтанно обучается выполнять поставленную задачу без вмешательства со стороны экспериментатора. С точки зрения кибернетики, это является одним из видов кибернетического эксперимента. Как правило, это пригодно только для задач, в которых известны описания множества объектов (обучающей выборки), и требуется обнаружить внутренние взаимосвязи, зависимости, закономерности, существующие между объектами.

#### Обучение с «подкреплением»

Обучение с подкреплением (Reinforcement Learning) – это метод машинного обучения, в котором наша система (агент) обучается методом проб и ошибок. Идея заключается в том, что агент взаимодействует со средой, параллельно обучаясь, и получает вознаграждение за выполнение действий.

### Регрессия

**Регрессия** — статистическая зависимость среднего значения случайной величины от значений другой случайной величины или нескольких случайных величин.

- $h(x) = θ(0) + θ(1)x(1)$ – линейная регрессия
- $h(x) = θ(0) +f(x(1,2,3,…))$ - нелинейная регрессия

<img src="./images/regression_example.png">

#### Регрессия в машинном обучении

Стоимостная функция (или функция потерь - $J$) – оценка отклонения предсказанных значений от значений в реальной тестовой выборке. Должна быть минимизирована.

**Задача:** найти коэффициенты $(θ(i))$, при которых дисперсия и
стандартное отклонение будут минимальны.

Регрессионный анализ — поиск коэффициентов регрессии, при
которых стоимостная функция минимальна.

**Функция потерь (стоимостная функция):**


$$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2
$$

где:
- $J(\theta)$ — функция потерь
- $m$ — количество обучающих примеров
- $h_\theta(x^{(i)})$ — предсказанное значение для i-го примера
- $y^{(i)}$ — истинное значение для i-го примера
- $\theta$ — вектор параметров модели

#### Обучающий алгоритм Ньютона (Рафтона)

- `Repeat` {выбор регрессионной функции}
- `Repeat { //(Cycle for selecting the appropriate coefficients)` 
    - `Repeat (j) {`
    - $\theta_j = 0$
      - `For i=0 to N`
      - Считаем $\theta_j$ (формула ниже)
      - `If` $(J(Ɵj))<J(j)$ `then` $J(j)=J(Ɵj)$
      - `Next I`
    - `Inc(j)`
- `}}`

**Дополнение от Рафтона:** α — 0..1 — шаг изменения для θ.

**Формула вычисления $θ_j$ (градиентный спуск):**

$$
\theta_j := \theta_j + \alpha \sum_{i=1}^{m} (y^{(i)} - h_\theta(x^{(i)})) \cdot x_j^{(i)}
$$

где:
- $\theta_j$ — j-й параметр модели;
- $\alpha$ — скорость обучения (learning rate), значение от 0 до 1;
- $m$ — количество обучающих примеров;
- $x_j^{(i)}$ — значение j-го признака в i-м примере.

### Библиотека Scikit-learn

www.scikit-learn.org

Open-source инструменты для работы с нейросетями.

### Основные инструменты

- IBM SPS Statistics
- PSPP
- MatLab
- Octave

## [Модуль 4] Задачи классификации и распознавания образов, видео, речи, текста. Понятие нейронных сетей. Примеры применения

### Сегментирование данных (slice & dice)

В контексте машинного обучения и, в частности, логистической регрессии, выражение "slice and dice" (разрезать и нарезать кубиками) используется в переносном смысле и означает детальный, многомерный анализ данных.

<img src="./images/segments.png">

#### Метод опорных векторов

##### Анализ текста. Задача кластеризации: спам-фильтр

**Задача:** выделить e-мейлы, относящиеся к спаму (на примере 2х факторов):
- х1 — количество определённых слов;
- х2 — объём вложений.

<img src="./images/support-vecs.png">

##### Задача кластеризации: медицина

**Задача:** выделить кластер пациентов с заболеванием щитовидной железы.

<img src="./images/support-vecs-2.png">

#### К – кластерный анализ

<img src="./images/k-clusters.png">

### Ассоциативные правила

Ассоциативное правило устанавливается между множествами $X$ и $Y$:

$$
X \Rightarrow Y \quad [S\%, C\%]
$$

где $X$, $Y$ — продукты и/или услуги (например).

**Параметры:**
- $X$ — левосторонний элемент или предшественник;
- $Y$ — правосторонний элемент или последователь;
- $S$ (Support) — критерий поддержки гипотезы;
- $C$ (Confidence) — критерий гарантии (уверенности).

**Пример:** Ассоциативные правила – основной инструмент, используемый Amazon.

**Формула поддержки (Support):**

$$
S(X \Rightarrow Y) = \frac{|X \cap Y|}{N}
$$

где:
- $|X \cap Y|$ — количество транзакций, содержащих и $X$, и $Y$;
- $N$ — общее количество транзакций.

**Интерпретация:** Как часто элементы $X$ и $Y$ встречаются вместе в общей выборке.

**Формула уверенности (Confidence):**

$$
C(X \Rightarrow Y) = \frac{|X \cap Y|}{|X|} = \frac{S(X \cap Y)}{S(X)}
$$

где:
- $|X \cap Y|$ — количество транзакций, содержащих и $X$, и $Y$;
- $|X|$ — количество транзакций, содержащих $X$.

**Интерпретация:** Как часто $Y$ идёт совместно с $X$ из общего числа элементов $X$.

#### Пример: анализ покупок в магазине электроники

**Правило:** Ноутбук ⇒ Гарнитура

**Данные о покупках клиентов:**

| № | Покупки клиента |
|---|---|
| 1 | Ноутбук, принтер, планшет, гарнитура |
| 2 | Монитор, принтер, планшет |
| 3 | Ноутбук, принтер, планшет, гарнитура |
| 4 | Ноутбук, монитор, планшет, гарнитура |
| 5 | Монитор, принтер, планшет, гарнитура |
| 6 | Принтер, планшет, гарнитура |
| 7 | Монитор, планшет |
| 8 | Ноутбук, принтер, монитор |
| 9 | Ноутбук, планшет, гарнитура |
| 10 | Принтер, гарнитура |

**Подсчёт:**
- $X$ (Ноутбук): встречается в транзакциях 1, 3, 4, 8, 9 → $|X| = 5$
- $Y$ (Гарнитура): встречается в транзакциях 1, 3, 4, 5, 6, 9, 10 → $|Y| = 7$
- $X \cap Y$ (оба товара): встречается в транзакциях 1, 3, 4, 9 → $|X \cap Y| = 4$
- $N$ (всего транзакций) = 10

**Расчёт метрик:**

$$
S(\text{Ноутбук} \Rightarrow \text{Гарнитура}) = \frac{|X \cap Y|}{N} = \frac{4}{10} = 0.4 = 40\%
$$

$$
C(\text{Ноутбук} \Rightarrow \text{Гарнитура}) = \frac{|X \cap Y|}{|X|} = \frac{4}{5} = 0.8 = 80\%
$$

**Результат:** Ноутбук ⇒ Гарнитура [40%, 80%]

**Интерпретация:**
- **Support = 40%:** В 40% всех покупок клиенты покупают и ноутбук, и гарнитуру вместе.
- **Confidence = 80%:** Из всех клиентов, купивших ноутбук, 80% также покупают гарнитуру.

**Вывод:** Это сильное ассоциативное правило. Рекомендуется размещать гарнитуры рядом с ноутбуками или предлагать их в качестве дополнительного товара при покупке ноутбука.

#### Метод перебора для поиска ассоциативных правил

**Задача:** Найти все значимые ассоциативные правила в данных о покупках.

**Алгоритм поиска методом перебора:**

**Шаг 1. Определение всех уникальных товаров**

Из 10 транзакций выделяем уникальные товары:
- Ноутбук
- Монитор
- Принтер
- Планшет
- Гарнитура

**Шаг 2. Генерация всех возможных пар (правил X ⇒ Y)**

Перебираем все возможные комбинации товаров:

| № | Правило | $\|X\|$ | $\|Y\|$ | $\|X \cap Y\|$ | Support | Confidence |
|---|---|---|---|---|---|---|
| 1 | Ноутбук ⇒ Монитор | 5 | 4 | 2 | 20% | 40% |
| 2 | Ноутбук ⇒ Принтер | 5 | 6 | 3 | 30% | 60% |
| 3 | Ноутбук ⇒ Планшет | 5 | 8 | 4 | 40% | 80% |
| 4 | **Ноутбук ⇒ Гарнитура** | **5** | **7** | **4** | **40%** | **80%** |
| 5 | Монитор ⇒ Ноутбук | 4 | 5 | 2 | 20% | 50% |
| 6 | Монитор ⇒ Принтер | 4 | 6 | 3 | 30% | 75% |
| 7 | Монитор ⇒ Планшет | 4 | 8 | 4 | 40% | 100% |
| 8 | Монитор ⇒ Гарнитура | 4 | 7 | 2 | 20% | 50% |
| 9 | Принтер ⇒ Ноутбук | 6 | 5 | 3 | 30% | 50% |
| 10 | Принтер ⇒ Монитор | 6 | 4 | 3 | 30% | 50% |
| 11 | Принтер ⇒ Планшет | 6 | 8 | 5 | 50% | 83% |
| 12 | Принтер ⇒ Гарнитура | 6 | 7 | 4 | 40% | 67% |
| 13 | Планшет ⇒ Ноутбук | 8 | 5 | 4 | 40% | 50% |
| 14 | Планшет ⇒ Монитор | 8 | 4 | 4 | 40% | 50% |
| 15 | Планшет ⇒ Принтер | 8 | 6 | 5 | 50% | 63% |
| 16 | Планшет ⇒ Гарнитура | 8 | 7 | 5 | 50% | 63% |
| 17 | Гарнитура ⇒ Ноутбук | 7 | 5 | 4 | 40% | 57% |
| 18 | Гарнитура ⇒ Монитор | 7 | 4 | 2 | 20% | 29% |
| 19 | Гарнитура ⇒ Принтер | 7 | 6 | 4 | 40% | 57% |
| 20 | Гарнитура ⇒ Планшет | 7 | 8 | 5 | 50% | 71% |

**Шаг 3. Применение порогов (минимальных значений)**

Устанавливаем пороговые значения:
- Минимальный Support: 40%
- Минимальный Confidence: 70%

**Шаг 4. Фильтрация правил**

Отбираем правила, удовлетворяющие обоим критериям:

| Правило | Support | Confidence | Статус |
|---|---|---|---|
| **Ноутбук ⇒ Гарнитура** | 40% | 80% | ✓ Подходит |
| **Монитор ⇒ Планшет** | 40% | 100% | ✓ Подходит |
| **Принтер ⇒ Планшет** | 50% | 83% | ✓ Подходит |
| **Гарнитура ⇒ Планшет** | 50% | 71% | ✓ Подходит |

**Примечание:** Ассоциативные правила, обычно, принимают как работающие при $S>33\%$ и $С > 50\%$.

**Результат перебора:**

Найдено 4 сильных ассоциативных правила. Правило **Ноутбук ⇒ Гарнитура** является одним из наиболее значимых с точки зрения уверенности (80%).

**Примечание:** В реальных задачах с большим количеством товаров используются оптимизированные алгоритмы (Apriori, FP-Growth), которые не требуют полного перебора всех комбинаций.

### Нейронные сети

- **Искусственные нейронные сети** (ИНС) — математические модели, а также их программные или аппаратные реализации, построенные по принципу организации и функционирования биологических нейронных сетей — сетей нервных клеток живого организма. Это понятие возникло при изучении процессов, протекающих в мозге, и при попытке смоделировать эти процессы.

- **ИНС** представляют собой систему соединённых и взаимодействующих между собой простых процессоров (искусственных нейронов). Каждый процессор подобной сети имеет дело только с сигналами, которые он периодически получает, и сигналами, которые он периодически посылает другим процессорам.

- Нейронные сети не программируются в привычном смысле этого слова, они **обучаются**. Технически обучение заключается в нахождении коэффициентов связей между нейронами. В процессе обучения нейронная сеть способна выявлять сложные зависимости между входными данными и выходными, а также выполнять обобщение.

#### Решаемые задачи

- Распознавание образов
  - Символы
  - Речь
  - Штрих- и QR-коды
  - Лица
- Прогнозирование
- Искусственный интеллект (AI) первого рода

#### Структура искусственного нейрона

Искусственный нейрон (перцептрон) — базовая вычислительная единица нейронной сети, имитирующая работу биологического нейрона.

**Основные компоненты нейрона:**

1. **Входы** ($x_1, x_2, ..., x_n$) — входные сигналы (признаки)
2. **Веса** ($w_1, w_2, ..., w_n$) — коэффициенты важности каждого входа
3. **Смещение** ($b$, bias) — пороговое значение активации
4. **Сумматор** ($\Sigma$) — вычисляет взвешенную сумму входов
5. **Функция активации** ($f$) — нелинейное преобразование суммы
6. **Выход** ($y$) — результат работы нейрона

**Математическая модель нейрона:**

$$
y = f\left(\sum_{i=1}^{n} w_i \cdot x_i + b\right) = f(w_1x_1 + w_2x_2 + ... + w_nx_n + b)
$$

**Структурная схема нейрона:**

```mermaid
graph LR
    %% Входные сигналы
    x1((x₁)) --> |w₁| sum
    x2((x₂)) --> |w₂| sum
    x3((x₃)) --> |w₃| sum
    xn((xₙ)) -.->|wₙ| sum
    
    %% Сумматор
    sum[Σ<br/>Сумматор<br/>Σwᵢxᵢ] --> activation
    
    %% Функция активации
    activation[f<br/>Функция<br/>активации] --> output
    
    %% Выход
    output((Y</br> Выход; Вход для следующего нейрона))
    
    %% Стилизация
    style sum fill:#e1f5ff,stroke:#0288d1,stroke-width:2px
    style activation fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style output fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style x1 fill:#fce4ec,stroke:#c2185b
    style x2 fill:#fce4ec,stroke:#c2185b
    style x3 fill:#fce4ec,stroke:#c2185b
    style xn fill:#fce4ec,stroke:#c2185b
```

#### 1. Функция активации Step (Пороговая)

$$
\text{step}(x) = \begin{cases} 
0, & \text{если } x < 0 \\
1, & \text{если } x \geq 0
\end{cases}
$$

<svg width="200" height="120" xmlns="http://www.w3.org/2000/svg">
  <line x1="30" y1="60" x2="200" y2="60" stroke="#ccc" stroke-width="1"/>
  <line x1="100" y1="10" x2="100" y2="110" stroke="#ccc" stroke-width="1"/>
  <path d="M 35,105 L 100,105 L 100,15 L 165,15" stroke="#ff6f00" fill="none" stroke-width="3"/>
  <text x="5" y="20" font-size="11" fill="#666">1</text>
  <text x="5" y="110" font-size="11" fill="#666">0</text>
</svg>

Диапазон: {0, 1} — самая простая, моментальный скачок в точке x=0

#### 2. Функция активации ReLU

$$
\text{ReLU}(x) = \max(0, x) = \begin{cases} 
x, & \text{если } x \geq 0 \\
0, & \text{если } x < 0
\end{cases}
$$

<svg width="200" height="120" xmlns="http://www.w3.org/2000/svg">
  <line x1="30" y1="60" x2="200" y2="60" stroke="#ccc" stroke-width="1"/>
  <line x1="100" y1="0" x2="100" y2="120" stroke="#ccc" stroke-width="1"/>
  <path d="M 35,60 L 100,60 L 165,15" stroke="#388e3c" fill="none" stroke-width="3"/>
  <text x="5" y="65" font-size="11" fill="#666">0</text>
  <text x="5" y="20" font-size="11" fill="#666">+</text>
</svg>

Диапазон: [0, +∞) — две прямые линии: горизонталь (0) слева, наклон 45° справа

#### 3. Функция активации Leaky ReLU

$$
\text{LeakyReLU}(x) = \begin{cases} 
x, & \text{если } x \geq 0 \\
\alpha x, & \text{если } x < 0
\end{cases}
\quad (\alpha = 0.01)
$$

<svg width="200" height="120" xmlns="http://www.w3.org/2000/svg">
  <line x1="30" y1="60" x2="200" y2="60" stroke="#ccc" stroke-width="1"/>
  <line x1="100" y1="0" x2="100" y2="120" stroke="#ccc" stroke-width="1"/>
  <path d="M 35,70 L 100,60 L 165,15" stroke="#e91e63" fill="none" stroke-width="3"/>
  <text x="5" y="65" font-size="11" fill="#666">0</text>
  <text x="5" y="20" font-size="11" fill="#666">+</text>
</svg>

Диапазон: (-∞, +∞) — как ReLU, но слева небольшой наклон вместо нуля

#### 4. Функция активации Sigmoid (Логистическая)

**Для одного входа:**

$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

**Для N входов (логистическая регрессия):**

$$
\sigma(x_1, \ldots, x_n) = \frac{1}{1 + e^{-(w_1x_1 + \ldots + w_nx_n + b)}}
$$

<svg width="200" height="120" xmlns="http://www.w3.org/2000/svg">
  <line x1="30" y1="60" x2="200" y2="60" stroke="#ccc" stroke-width="1"/>
  <line x1="100" y1="10" x2="100" y2="110" stroke="#ccc" stroke-width="1"/>
  <path d="M 35,105 C 60,105 80,85 100,60 C 120,35 140,15 165,15" stroke="#2196F3" fill="none" stroke-width="3"/>
  <text x="5" y="20" font-size="11" fill="#666">1</text>
  <text x="5" y="65" font-size="11" fill="#666">0.5</text>
  <text x="5" y="110" font-size="11" fill="#666">0</text>
</svg>

Диапазон: (0, 1) — плавная S-образная кривая, экспоненциальная функция

#### 5. Функция активации Tanh

$$
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$

<svg width="200" height="120" xmlns="http://www.w3.org/2000/svg">
  <line x1="30" y1="60" x2="200" y2="60" stroke="#ccc" stroke-width="1"/>
  <line x1="100" y1="0" x2="100" y2="120" stroke="#ccc" stroke-width="1"/>
  <path d="M 35,105 C 60,105 80,90 100,60 C 120,30 140,15 165,15" stroke="#7b1fa2" fill="none" stroke-width="3"/>
  <text x="5" y="15" font-size="11" fill="#666">1</text>
  <text x="5" y="65" font-size="11" fill="#666">0</text>
  <text x="5" y="110" font-size="11" fill="#666">-1</text>
</svg>

Диапазон: (-1, 1) — плавная S-образная кривая через центр, симметричная относительно нуля

---

### Пример обученного нейрона

**Задача:** Определить, купит ли клиент товар (бинарная классификация)

```mermaid
graph LR
    %% Входные признаки
    x1((Возраст</br>35 лет)) --> |w₁=0.3| neuron
    x2((Доход</br>50k$)) --> |w₂=0.8| neuron
    x3((Посещений</br>сайта: 12)) --> |w₃=0.5| neuron
    x4((Время на</br>сайте: 45 мин)) --> |w₄=0.6| neuron
    
    %% Смещение
    bias[b=-2.1] --> neuron
    
    %% Нейрон с функцией активации
    neuron[Σ = 1.85</br>σ Sigmoid</br>y = 0.86]
    
    %% Выход
    neuron --> output((Купит!</br>86%))
    
    %% Стили
    style neuron fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style output fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style bias fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style x1 fill:#e3f2fd,stroke:#1976d2
    style x2 fill:#e3f2fd,stroke:#1976d2
    style x3 fill:#e3f2fd,stroke:#1976d2
    style x4 fill:#e3f2fd,stroke:#1976d2
```

**Расчёт:**

$$
\begin{aligned}
\Sigma &= w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + b \\
       &= 0.3 \cdot 35 + 0.8 \cdot 50 + 0.5 \cdot 12 + 0.6 \cdot 45 - 2.1 \\
       &= 10.5 + 40 + 6 + 27 - 2.1 = 81.4 \text{ (нормализовано до 1.85)} \\[0.5em]
y &= \sigma(1.85) = \frac{1}{1+e^{-1.85}} = 0.86 = 86\%
\end{aligned}
$$

**Интерпретация:** Нейрон предсказывает с вероятностью 86%, что клиент купит товар.

---

### Пример многослойной нейронной сети

**Архитектура:** 3 входа → 4 нейрона (слой 1) → 3 нейрона (слой 2) → 2 выхода

```mermaid
flowchart LR
    subgraph input["Входной слой"]
        i1((x₁))
        i2((x₂))
        i3((x₃))
    end
    
    subgraph hidden1["Скрытый слой 1"]
        h11((N₁₁))
        h12((N₁₂))
        h13((N₁₃))
        h14((N₁₄))
    end
    
    subgraph hidden2["Скрытый слой 2"]
        h21((N₂₁))
        h22((N₂₂))
        h23((N₂₃))
    end
    
    subgraph output["Выходной слой"]
        o1((y₁))
        o2((y₂))
    end
    
    %% Связи входной -> скрытый 1
    i1 --> h11
    i1 --> h12
    i1 --> h13
    i1 --> h14
    
    i2 --> h11
    i2 --> h12
    i2 --> h13
    i2 --> h14
    
    i3 --> h11
    i3 --> h12
    i3 --> h13
    i3 --> h14
    
    %% Связи скрытый 1 -> скрытый 2
    h11 --> h21
    h11 --> h22
    h11 --> h23
    
    h12 --> h21
    h12 --> h22
    h12 --> h23
    
    h13 --> h21
    h13 --> h22
    h13 --> h23
    
    h14 --> h21
    h14 --> h22
    h14 --> h23
    
    %% Связи скрытый 2 -> выходной
    h21 --> o1
    h21 --> o2
    
    h22 --> o1
    h22 --> o2
    
    h23 --> o1
    h23 --> o2
    
    %% Стили
    style i1 fill:#e3f2fd,stroke:#1976d2
    style i2 fill:#e3f2fd,stroke:#1976d2
    style i3 fill:#e3f2fd,stroke:#1976d2
    
    style h11 fill:#fff3e0,stroke:#f57c00
    style h12 fill:#fff3e0,stroke:#f57c00
    style h13 fill:#fff3e0,stroke:#f57c00
    style h14 fill:#fff3e0,stroke:#f57c00
    
    style h21 fill:#f3e5f5,stroke:#7b1fa2
    style h22 fill:#f3e5f5,stroke:#7b1fa2
    style h23 fill:#f3e5f5,stroke:#7b1fa2
    
    style o1 fill:#e8f5e9,stroke:#388e3c
    style o2 fill:#e8f5e9,stroke:#388e3c
```

**Структура сети:**

- **Входной слой:** 3 нейрона (признаки x₁, x₂, x₃)
- **Скрытый слой 1:** 4 нейрона (N₁₁, N₁₂, N₁₃, N₁₄) — оранжевые
- **Скрытый слой 2:** 3 нейрона (N₂₁, N₂₂, N₂₃) — фиолетовые
- **Выходной слой:** 2 нейрона (y₁, y₂) — зелёные (например, "класс А" и "класс Б")

**Обозначения:** Nᵢⱼ — j-й нейрон в i-м скрытом слое

**Полносвязная архитектура:** Каждый нейрон одного слоя соединён со **всеми** нейронами следующего слоя.

**Количество параметров:**
- Связи входной → скрытый 1: $3 \times 4 = 12$ весов
- Связи скрытый 1 → скрытый 2: $4 \times 3 = 12$ весов
- Связи скрытый 2 → выходной: $3 \times 2 = 6$ весов
- Смещения: $4 + 3 + 2 = 9$
- **Всего параметров:** $12 + 12 + 6 + 9 = 39$ обучаемых весов

**Обозначения:**
- $m = 4$ — количество слоёв (входной + 2 скрытых + выходной)
- Количество выходов обычно равно количеству классов в задаче классификации

#### Практический пример: нейросеть для распознавания фруктов (яблоко или груша)

**Задача:** Классификация фруктов на основе цвета (RGB) и формы

**Входные признаки (5 нейронов):**
- x₁ — R (красный компонент, 0-255, нормализованный к 0-1)
- x₂ — G (зелёный компонент, 0-255, нормализованный к 0-1)
- x₃ — B (синий компонент, 0-255, нормализованный к 0-1)
- x₄ — Шар (1 = круглая форма, 0 = не круглая)
- x₅ — Эллипс (1 = вытянутая форма, 0 = не вытянутая)

**One-hot encoding для формы:**
- Шар: [1, 0]
- Эллипс: [0, 1]

**Выходы:**
- y₁ — Вероятность "Яблоко"
- y₂ — Вероятность "Груша"

**Архитектура:** 5 входов → 5 нейронов (скрытый слой) → 2 выхода

```mermaid
flowchart LR
    subgraph input["Входной слой</br>(RGB + форма)"]
        i1((R</br>красный</br>x₁))
        i2((G</br>зелёный</br>x₂))
        i3((B</br>синий</br>x₃))
        i4((Шар</br>x₄))
        i5((Эллипс</br>x₅))
    end
    
    subgraph hidden["Скрытый слой</br>(Извлечение признаков)</br>ReLU активация"]
        h1((N₁))
        h2((N₂))
        h3((N₃))
        h4((N₄))
        h5((N₅))
    end
    
    subgraph output["Выходной слой</br>(Классификация)</br>Softmax активация"]
        o1((🍎</br>Яблоко</br>y₁))
        o2((🍐</br>Груша</br>y₂))
    end
    
    %% Связи входной -> скрытый
    i1 --> h1 & h2 & h3 & h4 & h5
    i2 --> h1 & h2 & h3 & h4 & h5
    i3 --> h1 & h2 & h3 & h4 & h5
    i4 --> h1 & h2 & h3 & h4 & h5
    i5 --> h1 & h2 & h3 & h4 & h5
    
    %% Связи скрытый -> выходной
    h1 --> o1 & o2
    h2 --> o1 & o2
    h3 --> o1 & o2
    h4 --> o1 & o2
    h5 --> o1 & o2
    
    %% Стили
    style i1 fill:#ffcdd2,stroke:#c62828,stroke-width:2px
    style i2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    style i3 fill:#bbdefb,stroke:#1565c0,stroke-width:2px
    style i4 fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    style i5 fill:#ffe0b2,stroke:#e65100,stroke-width:2px
    
    style h1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style h2 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style h3 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style h4 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style h5 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    style o1 fill:#c8e6c9,stroke:#388e3c,stroke-width:3px
    style o2 fill:#ffccbc,stroke:#d84315,stroke-width:3px
```

**Описание работы сети:**

1. **Входной слой:** Принимает 5 признаков
   - **3 нейрона для цвета:** RGB компоненты описывают цвет фрукта (например, красный для яблока, зеленовато-жёлтый для груши)
   - **2 нейрона для формы:** One-hot encoding [1,0] = шар (яблоко круглое), [0,1] = эллипс (груша вытянутая)

2. **Скрытый слой:** 5 нейронов с функцией активации ReLU
   - Каждый нейрон получает все 5 входов
   - Извлекает сложные признаки: комбинации цвета и формы (например, "красный + шар" → яблоко, "жёлто-зелёный + эллипс" → груша)
   - **Всего связей:** 5 × 5 = 25 весов + 5 смещений = **30 параметров**

3. **Выходной слой:** 2 нейрона с функцией активации Softmax
   - Каждый нейрон представляет класс (яблоко или груша)
   - Softmax нормализует выходы так, чтобы их сумма = 1 (интерпретируется как вероятности)
   - **Всего связей:** 5 × 2 = 10 весов + 2 смещения = **12 параметров**

4. **Общее количество обучаемых параметров:** 30 + 12 = **42 веса**

**Пример предсказания №1: Яблоко**

Дано: фрукт с признаками RGB(220, 53, 69) + форма = шар [1, 0]

```mermaid
flowchart LR
    subgraph input["Входные данные</br>(красное круглое)"]
        i1((R: 0.86</br>220/255))
        i2((G: 0.21</br>53/255))
        i3((B: 0.27</br>69/255))
        i4((Шар: 1))
        i5((Эллипс: 0))
    end
    
    subgraph hidden["Скрытый слой</br>после ReLU"]
        h1((0.91))
        h2((0.85))
        h3((0.22))
        h4((0.78))
        h5((0.67))
    end
    
    subgraph output["Результат</br>после Softmax"]
        o1((🍎 Яблоко</br>0.94 = 94%))
        o2((🍐 Груша</br>0.06 = 6%))
    end
    
    i1 --> h1 & h2 & h3 & h4 & h5
    i2 --> h1 & h2 & h3 & h4 & h5
    i3 --> h1 & h2 & h3 & h4 & h5
    i4 --> h1 & h2 & h3 & h4 & h5
    i5 --> h1 & h2 & h3 & h4 & h5
    
    h1 --> o1 & o2
    h2 --> o1 & o2
    h3 --> o1 & o2
    h4 --> o1 & o2
    h5 --> o1 & o2
    
    style i1 fill:#dc3545,stroke:#a71d2a,stroke-width:2px,color:#fff
    style i2 fill:#6c757d,stroke:#495057,stroke-width:2px,color:#fff
    style i3 fill:#6c757d,stroke:#495057,stroke-width:2px,color:#fff
    style i4 fill:#28a745,stroke:#1e7e34,stroke-width:3px,color:#fff
    style i5 fill:#e0e0e0,stroke:#9e9e9e,stroke-width:1px
    style o1 fill:#28a745,stroke:#1e7e34,stroke-width:4px,color:#fff
    style o2 fill:#ffebee,stroke:#d84315,stroke-width:1px
    style hidden fill:#fff3e0,stroke:#f57c00
```

**Интерпретация:** Красный круглый фрукт → нейросеть с уверенностью **94%** классифицирует как **яблоко** 🍎

**Пример предсказания №2: Груша**

Дано: фрукт с признаками RGB(212, 230, 140) + форма = эллипс [0, 1]

```mermaid
flowchart LR
    subgraph input2["Входные данные</br>(жёлто-зелёное вытянутое)"]
        i1((R: 0.83</br>212/255))
        i2((G: 0.90</br>230/255))
        i3((B: 0.55</br>140/255))
        i4((Шар: 0))
        i5((Эллипс: 1))
    end
    
    subgraph hidden2["Скрытый слой</br>после ReLU"]
        h1((0.18))
        h2((0.31))
        h3((0.88))
        h4((0.25))
        h5((0.92))
    end
    
    subgraph output2["Результат</br>после Softmax"]
        o1((🍎 Яблоко</br>0.08 = 8%))
        o2((🍐 Груша</br>0.92 = 92%))
    end
    
    i1 --> h1 & h2 & h3 & h4 & h5
    i2 --> h1 & h2 & h3 & h4 & h5
    i3 --> h1 & h2 & h3 & h4 & h5
    i4 --> h1 & h2 & h3 & h4 & h5
    i5 --> h1 & h2 & h3 & h4 & h5
    
    h1 --> o1 & o2
    h2 --> o1 & o2
    h3 --> o1 & o2
    h4 --> o1 & o2
    h5 --> o1 & o2
    
    style i1 fill:#d4e692,stroke:#a8b969,stroke-width:2px
    style i2 fill:#9ccc65,stroke:#689f38,stroke-width:2px
    style i3 fill:#aed581,stroke:#7cb342,stroke-width:2px
    style i4 fill:#e0e0e0,stroke:#9e9e9e,stroke-width:1px
    style i5 fill:#ff6f00,stroke:#e65100,stroke-width:3px,color:#fff
    style o2 fill:#ff6f00,stroke:#e65100,stroke-width:4px,color:#fff
    style o1 fill:#ffebee,stroke:#388e3c,stroke-width:1px
    style hidden2 fill:#fff3e0,stroke:#f57c00
```

**Интерпретация:** Жёлто-зелёный эллиптический фрукт → нейросеть с уверенностью **92%** классифицирует как **груша** 🍐

**Как происходит обучение:**
1. Подаём сети примеры с известными ответами (обучающая выборка)
2. Сравниваем выход сети с правильным ответом (вычисляем ошибку)
3. Методом обратного распространения корректируем веса
4. Повторяем процесс тысячи раз на разных примерах
5. Сеть "учится" распознавать паттерны: **красный + шар → яблоко**, **жёлто-зелёный + эллипс → груша**

**Типичные данные для обучения:**

| R | G | B | Шар | Эллипс | Класс |
|---|---|---|-----|--------|-------|
| 0.86 | 0.21 | 0.27 | 1 | 0 | 🍎 Яблоко (красное) |
| 0.91 | 0.15 | 0.18 | 1 | 0 | 🍎 Яблоко (красное) |
| 0.24 | 0.70 | 0.29 | 1 | 0 | 🍎 Яблоко (зелёное) |
| 0.18 | 0.75 | 0.22 | 1 | 0 | 🍎 Яблоко (зелёное) |
| 0.83 | 0.90 | 0.55 | 0 | 1 | 🍐 Груша |
| 0.78 | 0.85 | 0.48 | 0 | 1 | 🍐 Груша |
| 0.59 | 0.73 | 0.31 | 0 | 1 | 🍐 Груша |
| 0.67 | 0.82 | 0.41 | 0 | 1 | 🍐 Груша |
| ... | ... | ... | ... | ... | ... |

**Преимущества one-hot encoding для формы:**
- **Интерпретируемость:** Явное указание класса формы через активацию соответствующего нейрона
- **Отсутствие порядка:** Модель не предполагает, что "эллипс > шар" (как было бы при кодировании 0/1)
- **Расширяемость:** Легко добавить третью форму (например, "овал"), добавив ещё один входной нейрон

**Ключевые паттерны:**
- **Яблоко:** преобладание красного (высокий R) ИЛИ зелёного (высокий G) + круглая форма [1, 0]
- **Груша:** жёлто-зелёный оттенок (высокие G и R, средний B) + вытянутая форма [0, 1]

**Замечание:** В реальных приложениях для распознавания изображений фруктов используются **свёрточные нейронные сети (CNN)**, которые работают напрямую с пикселями изображения, автоматически извлекая RGB-компоненты и форму, а не получая их как заранее подготовленные признаки.

---

**Правила разбиения на выборки (для задач классификации):**

✅ **Требования к выборкам:**
1. Должны быть из **одной генеральной совокупности**
2. **Не должны пересекаться** (каждый пример попадает только в одну выборку)
3. Формируются **случайным образом** (random sampling)
4. Сохраняют **пропорции классов** (stratified sampling рекомендуется)

📌 **Назначение проверочной выборки (Dev/Validation):**
- Используется для **тонкой настройки** гиперпараметров модели
- Помогает **проверить гипотезы** об улучшении алгоритма
- Позволяет **сравнивать** разные версии модели без использования тестовой выборки

### Обучающие и тестовые выборки

**1. Обучающая выборка (Training Sample)**
- **Назначение:** настройка и оптимизация параметров модели
- **Размер:** ~**80%** от всех данных (рекомендация Andrew Ng)
- ⚠️ **Проблема:** оценка качества модели по той же выборке, на которой она обучалась, является **оптимистически смещённой** (завышенной)
- **Риск:** **переобучение** (overfitting) — модель запоминает обучающие данные, но плохо работает на новых

**2. Тестовая выборка (Test Sample)**
- **Назначение:** финальная оценка качества построенной модели
- **Размер:** ~**10%** от всех данных (рекомендация Andrew Ng)
- ✅ **Преимущество:** если обучающая и тестовая выборки независимы, оценка является **несмещённой** (объективной)
- **Важно:** тестовая выборка НЕ используется при обучении

**3. Проверочная выборка (Validation Sample)**
- **Назначение:** выбор наилучшей модели из нескольких кандидатов
- **Размер:** ~**10%** от всех данных (оставшиеся после обучающей и тестовой)
- **Использование:** для подбора гиперпараметров и сравнения разных архитектур

**Типичное разбиение данных:**
- 🟦 Обучающая (Training): **80%**
- 🟨 Проверочная (Validation): **10%**
- 🟩 Тестовая (Test): **10%**

---

Обучающая выборка должна представлять все возможные варианты из генеральной выборки но в меньшем количестве, наприме при выборе фруктов если в генеральной выборке 30% груш и из них 5% покусанных, то в обучающей выборке это соотношение желаетльно сохранить.

### Классы методов обучения нейросети

**1. Обратное распространение ошибки (Backpropagation)**
- Самый популярный метод обучения нейросетей
- Вычисляет градиент функции потерь и распространяет ошибку от выхода к входу
- Использует градиентный спуск для корректировки весов: $w_{new} = w_{old} - \alpha \cdot \frac{\partial L}{\partial w}$
- **Плюсы:** быстрый, эффективный для больших сетей
- **Минусы:** может застрять в локальных минимумах

**2. Генетический алгоритм (Genetic Algorithm)**
- Имитирует естественный отбор: создание популяции сетей, отбор лучших, скрещивание, мутация
- Не требует вычисления градиентов
- **Плюсы:** не застревает в локальных минимумах, подходит для дискретных параметров
- **Минусы:** медленный, требует много вычислительных ресурсов

**3. Упругое распространение (Resilient Propagation, RProp)**
- Модификация **backpropagation**: использует только знак градиента, игнорируя величину
- Адаптивный шаг обучения для каждого веса индивидуально
- **Плюсы:** быстрее сходится, меньше гиперпараметров
- **Минусы:** не подходит для мини-батчей, используется реже **backpropagation**

### Обратное распространение

#### Стоимостная функция 

Стоимостная функция это сумма ошибок (по аналогии с регрессией, где стоимостная функция это дисперсия).

#### Алгоритм нахождения стоимостной функции

Ищем
$$
\min_\theta J(\theta)
$$

**Цель оптимизации:**
- $\min_\theta$ — минимизация по параметрам $\theta$
- $J(\theta)$ — функция потерь, которую мы хотим минимизировать
- Задача: найти такие значения параметров $\theta$, при которых ошибка модели будет наименьшей

- `Repeat (j) {`
  - Вычисляем $\theta_j$
  - Вычислить $J(\theta)$
  - Если $J(\theta_j) < J(j)$ то $J(j) = J(\theta_j)$
  - `next i`
- `inc j`

**Градиентный спуск:**

$$
\theta_j := \theta_j - \alpha \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}
$$

где:
- $\theta_j$ — j-й параметр (коэффициент) модели, который мы оптимизируем
- $\alpha$ — скорость обучения (learning rate), определяет размер шага при обновлении параметров
- $m$ — количество обучающих примеров в выборке
- $h_\theta(x^{(i)})$ — предсказанное значение модели для i-го примера
- $y^{(i)}$ — истинное (реальное) значение для i-го примера
- $x_j^{(i)}$ — значение j-го признака для i-го примера

**Функция потерь (логистическая регрессия):**

$$
J(\theta) = -\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)}) \log (1 - h_\theta(x^{(i)}))\right]
$$

где:
- $J(\theta)$ — функция потерь (cost function), которая измеряет ошибку модели
- $\theta$ — вектор всех параметров модели $(\theta_0, \theta_1, ..., \theta_n)$
- $m$ — количество обучающих примеров
- $y^{(i)}$ — истинная метка класса для i-го примера (0 или 1 для бинарной классификации)
- $h_\theta(x^{(i)})$ — предсказанная вероятность того, что $y=1$ для i-го примера
- $\log$ — натуральный логарифм

**Интерпретация:**
- Если $y^{(i)} = 1$: штраф равен $-\log h_\theta(x^{(i)})$ (чем ближе предсказание к 1, тем меньше потери)
- Если $y^{(i)} = 0$: штраф равен $-\log(1 - h_\theta(x^{(i)}))$ (чем ближе предсказание к 0, тем меньше потери)

**Типы ошибок в формуле:**

1. **Ложноотрицательные ошибки (False Negative, FN):**
   - Компонент формулы: $y^{(i)} \log h_\theta(x^{(i)})$
   - Когда: $y^{(i)} = 1$ (реально положительный класс), но $h_\theta(x^{(i)}) \approx 0$ (предсказали отрицательный)
   - Штраф: $-\log(0) \to \infty$ — очень большая потеря за пропущенный положительный случай

2. **Ложноположительные ошибки (False Positive, FP):**
   - Компонент формулы: $(1 - y^{(i)}) \log (1 - h_\theta(x^{(i)}))$
   - Когда: $y^{(i)} = 0$ (реально отрицательный класс), но $h_\theta(x^{(i)}) \approx 1$ (предсказали положительный)
   - Штраф: $-\log(0) \to \infty$ — очень большая потеря за ложное срабатывание

**Балансировка ошибок:**
- Формула одинаково штрафует оба типа ошибок
- Для дисбаланса классов можно использовать взвешенную функцию потерь

##### Пример

**Архитектура нейросети для классификации объектов:**

```mermaid
graph LR
    subgraph Вход
        R((R))
        G((G))
        B((B))
        Шар((Шар))
        Эллипс((Эллипс))
    end
    
    subgraph Скрытый_слой_1["Скрытый слой 1"]
        a1((a1))
        a2((a2))
        a3((a3))
    end
    
    subgraph Скрытый_слой_2["Скрытый слой 2"]
        b1((b1))
        b2((b2))
        b3((b3))
    end
    
    subgraph Выход["Класс 3: Результат"]
        Яблоко((Яблоко))
        Груша((Груша))
    end
    
    R --> a1
    R --> a2
    R --> a3
    G --> a1
    G --> a2
    G --> a3
    B --> a1
    B --> a2
    B --> a3
    Шар --> a1
    Шар --> a2
    Шар --> a3
    Эллипс --> a1
    Эллипс --> a2
    Эллипс --> a3
    
    a1 --> b1
    a1 --> b2
    a1 --> b3
    a2 --> b1
    a2 --> b2
    a2 --> b3
    a3 --> b1
    a3 --> b2
    a3 --> b3
    
    b1 --> Яблоко
    b1 --> Груша
    b2 --> Яблоко
    b2 --> Груша
    b3 --> Яблоко
    b3 --> Груша
    
    style R fill:#4682B4
    style G fill:#4682B4
    style B fill:#4682B4
    style Шар fill:#4682B4
    style Эллипс fill:#4682B4
    style a1 fill:#5B9BD5
    style a2 fill:#5B9BD5
    style a3 fill:#5B9BD5
    style b1 fill:#5B9BD5
    style b2 fill:#5B9BD5
    style b3 fill:#5B9BD5
    style Яблоко fill:#4682B4
    style Груша fill:#4682B4
```

**Описание сети:**
- **Входной слой:** 5 признаков (R, G, B — цветовые каналы; Шар, Эллипс — форма)
- **Скрытый слой 1:** 3 нейрона (a1, a2, a3)
- **Скрытый слой 2:** 3 нейрона (b1, b2, b3)
- **Выходной слой:** 2 класса (Яблоко, Груша)
- **Всего весов:** 5×3 + 3×3 + 3×2 = 15 + 9 + 6 = 30 весов + смещения

**Веса на шаге 1 (заполнены какой-то константой, в нашем случае 0):**

Входной → Скрытый слой 1:
- $W(R, a1) = 0$
- $W(G, a1) = 0$
- $W(B, a1) = 0$
- $W(Шар, a1) = 0$
- $W(Эллипс, a1) = 0$
- $...$

Вычисляем $J(1)$

**Начальное значение функции потерь:** $J(\theta_0) = ?$ (вычисляется после первого прямого прохода)

**Процесс обучения:**
1. Прямое распространение с начальными весами
2. Вычисление ошибки для каждого класса
3. Обратное распространение градиентов
4. Обновление весов по формуле градиентного спуска
5. Повторение до минимизации $J(\theta)$

**Шаг 2 - После первой итерации обучения:**

Входной → Скрытый слой 1:
- $W(R, a1) = 0$
- $W(G, a1) = 0$
- $W(B, a1) = 0$
- $W(Шар, a1) = 0$
- $W(Эллипс, a2) = 0$
- $...$
- $W(Яблоко, b1) = 0$
- $W(Яблоко, b2) = 0 + 0.1 = 0.1$ ← вес изменился


**Значение функции потерь:** $J(\theta_2) < J(\theta_1)$ (ошибка уменьшилась)

#### Классы оптимизации обратного распространения

##### Направленное распространение

Веса изначально выставляются посередине. На следующем шаге все веса увеличиваются и сравниваются потери точности, если они стали меньше, то продолжаем увеличивать веса, если нет то начинаем уменьшать.

##### Рекурентный

...

##### Свёрточные сети

...

### Генетический алгоритм

**Определение:**

Эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов, аналогичных естественному отбору в природе.

#### Схема генетического алгоритма для обучения нейросетей

```mermaid
flowchart TD
    Start([Начало]) --> Init[Инициализация популяции<br/>Создание N нейросетей<br/>со случайными весами]
    Init --> Eval[Оценка приспособленности<br/>Тестирование каждой сети<br/>на обучающих данных]
    Eval --> Check{Достигнут<br/>критерий<br/>остановки?}
    Check -->|Да| Best[Выбор лучшей<br/>нейросети]
    Best --> End([Конец])
    Check -->|Нет| Select[Селекция<br/>Отбор лучших сетей<br/>для размножения]
    Select --> Cross[Кроссовер<br/>Скрещивание весов<br/>родительских сетей]
    Cross --> Mutate[Мутация<br/>Случайное изменение<br/>некоторых весов]
    Mutate --> NewGen[Новое поколение<br/>Замена популяции]
    NewGen --> Eval
    
    style Start fill:#2E7D32,color:#fff
    style End fill:#2E7D32,color:#fff
    style Init fill:#5B9BD5,color:#fff
    style Eval fill:#5B9BD5,color:#fff
    style Select fill:#5B9BD5,color:#fff
    style Cross fill:#FF9800,color:#fff
    style Mutate fill:#F44336,color:#fff
    style NewGen fill:#5B9BD5,color:#fff
    style Best fill:#4CAF50,color:#fff
    style Check fill:#FFC107,color:#000
```

#### Применение к нейросетям

**1. Представление особи (индивида):**
- Каждая особь = нейросеть с определенным набором весов
- Гены = веса связей между нейронами
- Хромосома = вектор всех весов сети

**2. Функция приспособленности (Fitness):**
- Точность классификации на тестовой выборке
- Минимизация ошибки (MSE, Cross-Entropy)
- Возможны дополнительные критерии (скорость, размер сети)

**3. Селекция:**
- Отбор лучших сетей (по accuracy или минимальной ошибке)
- Методы: турнирная селекция, рулетка, ранговая

**4. Кроссовер (скрещивание весов):**
```
Родитель 1: [w₁=0.5, w₂=0.3, w₃=0.8, w₄=0.2]
Родитель 2: [w₁=0.1, w₂=0.7, w₃=0.4, w₄=0.9]
              ↓ (одноточечный кроссовер)
Потомок 1:  [0.5, 0.3 | 0.4, 0.9]
Потомок 2:  [0.1, 0.7 | 0.8, 0.2]
```

**5. Мутация:**
- Случайное изменение весов с малой вероятностью (обычно 1-5%)
- Добавление шума: $w_{new} = w_{old} + \mathcal{N}(0, \sigma)$
- Поддерживает разнообразие решений

**6. Критерии остановки:**
- Достижение требуемой точности
- Максимальное число поколений
- Отсутствие улучшений за N поколений

**Преимущества:**
- Не требует вычисления градиентов
- Глобальный поиск (избегает локальных минимумов)
- Параллелизуемость (каждая сеть оценивается независимо)

**Недостатки:**
- Медленнее градиентных методов
- Требует много вычислительных ресурсов
- Сложно настраивать гиперпараметры

---

**Особенности:**

- Обучается постепенно. До первого удачного решения может пройти много времени
- Ищет хорошее решение, но не лучшее (за счёт случайности генераций)

#### Области применения

- ABC анализ ресурсов компании (по Парето)
- Андеррайтинг
- Аппликационный скоринг
- Антифрод
- Майнинг
- Жизненный цикл клиента
- Задача коммивояжера
- Составление расписаний

### Основные понятия оценки дискретных моделей

#### Обозначения

**TP** — истинно-положительное решение;

**TN** — истинно-отрицательное решение;

**FP** — ложно-положительное решение;

**FN** — ложно-отрицательное решение.

#### Метрики качества классификации

**Аккуратность (Accuracy)**

Доля правильных предсказаний:

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN} \to 1
$$

**Точность (Precision)**

Доля истинно положительных среди всех предсказанных положительных:

$$
Precision = \frac{TP}{TP + FP}
$$

**Полнота (Recall)**

Доля истинно положительных среди всех реальных положительных:

$$
Recall = \frac{TP}{TP + FN}
$$

**F-мера (F-measure)**

⚠️ Не путать с коэффициентом Фишера!

Гармоническое среднее между точностью и полнотой:

$$
F = \frac{2 \times Precision \times Recall}{Precision + Recall}
$$

где:
- $Precision$ — точность модели
- $Recall$ — полнота модели

---

В разных задачах важны различные метрики оценки качества модели:

**Пример 1: Диагностика тяжелых заболеваний**
- Критична **полнота (Recall)** — важно не пропустить ни одного больного
- Лучше ложная тревога (FP), чем пропущенное заболевание (FN)
- Например, при диагностике рака важнее выявить всех потенциально больных

**Пример 2: Спам-фильтр**
- Критична **точность (Precision)** — важно не отправить важное письмо в спам
- Лучше пропустить спам (FN), чем заблокировать важное письмо (FP)
- Пользователь может сам удалить спам, но не увидит важное письмо в спаме

### Типы ошибок алгоритма

**Базис (BASE)**

Доля ошибок алгоритма на тренировочном множестве.

$$
BASE = \frac{\text{Количество ошибок на обучающей выборке}}{\text{Размер обучающей выборки}}
$$

**Отклонение (VARIANCE)**

Разница в доле ошибок на тестовой и тренировочной выборках. Показывает степень переобучения модели.

$$
VARIANCE = \text{Ошибка на тесте} - \text{Ошибка на обучении}
$$

**Пример:**

- Количество ошибок на тренировочной выборке: **15%**. $BASE = 15\%$
- Количество ошибок на тестовой выборке: **20%**. $VARIANCE = 20\% - 15\% = 5\%$

**Интерпретация:**
- **Высокий BASE** — модель недообучена (underfitting), не может хорошо описать даже обучающие данные
- **Высокий VARIANCE** — модель переобучена (overfitting), хорошо запомнила обучающие данные, но плохо обобщает на новые
- **Идеал** — низкие значения и BASE, и VARIANCE

#### Корректировка ошибок базиса

- **Базисное отклонение требует первоочередной коррекции алгоритма**

- **Увеличение объема выборки при неприемлемом базисном отклонении не приведет к улучшению результата.**

**Важно:** Если модель плохо работает даже на обучающих данных (высокий BASE), то добавление новых данных не поможет. Сначала нужно улучшить саму модель (увеличить сложность, добавить признаки, изменить архитектуру).

#### Как уменьшить отклонение (VARIANCE)

Если алгоритм «недотренирован» (underfitting):

1. **Расширить охват (а не просто объем) выборки**
   - Добавить больше разнообразных примеров
   - Увеличить покрытие различных случаев и сценариев
   - Не просто дублировать похожие данные, а добавлять новые паттерны

2. **Провести дополнительную настройку («тренировку») алгоритма**
   - Увеличить число эпох обучения
   - Настроить гиперпараметры
   - Применить регуляризацию для уменьшения переобучения

### Анализ ошибок обучения

#### Метод быстрых проб и ошибок (fail fast)

1. **Отобрать до 100 примеров из множества разработки, которые были классифицированы неверно, и провести ручной анализ**

2. **Исключить или дополнительно обработать элементы, которые не удалось классифицировать вручную**
   - Удалить шумные или некорректные данные
   - Вынести в отдельную категорию неоднозначные случаи

3. **Отобрать наиболее частые ошибки и сосредоточиться на них**
   - Проанализировать паттерны ошибок
   - Выявить систематические проблемы модели

4. **Протестировать на выборке разработчика несколько конкурирующих идей**
   - Быстро проверить различные подходы к решению
   - Выбрать наиболее перспективное направление

### Ручная корректировка. Задачи аналитика и ученого по данным

**Если множество разработчика (dev) слишком велико для ручного анализа, разбейте его на 2:**

- **Ручное (Eyeball, 5-10% от dev)** — небольшая выборка для детального ручного анализа
- **Черный ящик (Blackbox)** — остальная часть для автоматической валидации
- **Проверьте гипотезы, сделанные вручную на множестве черного ящика**

**Цель:** Эффективно использовать время аналитика на самые показательные примеры, а затем валидировать выводы на большей выборке.

### Избыточное обучение (Overfit)

**Визуальный пример:**

<img src="./images/overfit.png">

- **Парабола черным цветом** — норма (правильная обобщающая модель)
- **Зеленая кривая** — переобучение (модель слишком точно подстроилась под обучающие данные)

**Признаки переобучения:**
- Модель идеально работает на обучающих данных
- На тестовых данных качество резко падает
- Модель запомнила данные вместо того, чтобы выучить закономерности
- Высокое значение VARIANCE

**Способы борьбы с переобучением:**
1. Увеличить объем обучающих данных
2. Применить регуляризацию (L1, L2, Dropout)
3. Упростить модель (уменьшить число параметров)
4. Использовать cross-validation
5. Early stopping (остановка обучения до переобучения)

### Регуляризация

**Осознанное упрощение избыточно сложной модели:**

- **Уменьшение числа рассматриваемых факторов** — отбор наиболее важных признаков, удаление шумовых и избыточных переменных
- **Применение линейной регрессии вместо более сложных подходов** — использование более простых моделей, которые лучше обобщают

**Методы регуляризации:**

1. **L1-регуляризация (Lasso)**
   - Добавляет штраф на сумму абсолютных значений весов
   - Приводит к разреженности (некоторые веса становятся равны 0)
   - Автоматический отбор признаков

2. **L2-регуляризация (Ridge)**
   - Добавляет штраф на сумму квадратов весов
   - Уменьшает веса, но не обнуляет их
   - Предотвращает слишком большие значения весов

3. **Elastic Net**
   - Комбинация L1 и L2 регуляризации
   - Баланс между отбором признаков и уменьшением весов

## [Модуль 5] Задачи классификации и распознавания образов, видео, речи, текста. Понятие нейронных сетей. Примеры применения

### Иерархия областей искусственного интеллекта

```mermaid
graph TB
    subgraph AI["Искусственный интеллект"]
        subgraph ML["Машинное обучение"]
            subgraph NN["Нейронные сети"]
                subgraph GM["Генеративные модели"]
                    GenAI["[GenAI] Генеративный ИИ<br/>Использует алгоритмы и модели для создания новых данных на основе существующих"]
                end
            end
        end
    end
    
    style AI fill:#f5f5f5,stroke:#2C3E50,stroke-width:3px
    style ML fill:#e8e8e8,stroke:#34495E,stroke-width:3px
    style NN fill:#d8d8d8,stroke:#5D6D7E,stroke-width:3px
    style GM fill:#c8c8c8,stroke:#7F8C8D,stroke-width:3px
    style GenAI fill:#95A5A6,stroke:#7F8C8D,stroke-width:2px,color:#000
```

**Структура областей (от центра к краям):**

1. **Генеративный ИИ (GenAI)** — самая узкая, современная область
   - Использует алгоритмы и модели для создания новых данных на основе существующих
   - Примеры: ChatGPT, DALL-E, Midjourney, Stable Diffusion

2. **Генеративные модели (Generative Models)** ⊃ GenAI
   - Подмножество нейросетей для генерации данных
   - Включает: GANs, VAE, Diffusion models и др.

3. **Нейронные сети (Neural Networks)** ⊃ Generative Models
   - Подмножество МО, основанное на структуре мозга
   - Используют искусственные нейроны и слои

4. **Машинное обучение (ML)** ⊃ Neural Networks
   - Подмножество ИИ, где системы обучаются на данных
   - Включает различные алгоритмы обучения (не только нейросети)

5. **Искусственный интеллект (AI)** — самая широкая область
   - Включает все методы имитации человеческого интеллекта
   - Охватывает как машинное обучение, так и другие подходы

### Роль ИИ в зависимости от сложности задачи и исполнителя

<img src="./images/airoles.png">

**Три зоны применения ИИ:**

**1. Автоматизация** (левая нижняя зона)
- Машина полностью выполняет задачи без участия человека
- Примеры: генерация отчётов, анализ документации
- Низкая сложность + минимальное участие человека

**2. Помощь** (центральная зона)
- Совместная работа человека и ИИ
- Примеры: планирование, подведение итогов совещания, анализ выгоды и затрат, анализ риска
- Средняя сложность + партнёрство человека и машины

**3. Поддержка** (правая верхняя зона)
- Человек принимает ключевые решения, ИИ предоставляет аналитику и рекомендации
- Примеры: принятие решения по проекту, создание бизнес-кейса
- Высокая сложность + критическая роль человека

**Вывод:** Чем сложнее и ответственнее задача, тем больше требуется участие и контроль человека. Рутинные задачи эффективно автоматизируются ИИ.

### Deep Machine Learning (Глубокое обучение)

**Определение:**

Глубокое (глубинное) обучение — набор алгоритмов машинного обучения, в которых понятия более высокого уровня определяются на основе понятий более низкого уровня.

**Ключевые особенности:**

- **Иерархическая структура** — многослойные нейронные сети с множеством скрытых слоев
- **Автоматическое извлечение признаков** — каждый слой обучается представлениям всё более высокого уровня абстракции
- **Обучение представлениям** — модель сама выявляет важные характеристики данных без ручной разработки признаков

**Совокупность методов машинного обучения:**

Глубокое обучение объединяет различные подходы:
- **С учителем** (supervised) — обучение на размеченных данных
- **С частичным привлечением учителя** (semi-supervised) — комбинация размеченных и неразмеченных данных
- **Без учителя** (unsupervised) — обучение на неразмеченных данных для поиска скрытых закономерностей
- **С подкреплением** (reinforcement) — обучение через взаимодействие со средой и получение наград

**Пример отличия глубокого обучения от простого машинного обучения:**

**Задача:** Распознавание рукописных букв

- **Простое МО:** 
  - Требует предзагруженных образцов для сравнения
  - Работает с явно заданными признаками
  - Ограниченная способность к обобщению

- **Глубокое обучение (ГО):**
  - За счёт наличия дополнительных скрытых слоёв возможно обучение абстрактному представлению
  - Модель самостоятельно выявляет иерархию признаков (от простых линий до сложных форм букв)
  - Обучается на основе опыта, не требуя заранее определённых шаблонов
  - Высокая способность к обобщению на новые примеры

**Применение:**
- Компьютерное зрение (распознавание образов, детекция объектов)
- Обработка естественного языка (NLP)
- Распознавание речи
- Генеративные модели (GANs, Diffusion models)
- Автономные системы

### Генеративные сети (GPT, GAN, LLM)

**Генеративное моделирование** — это задача машинного обучения без учителя (неконтролируемое обучение), которая заключается в автоматическом обнаружении закономерностей и зависимостей во входных данных, которые можно было бы использовать для генерации на выходе новых примеров, которые могли бы непротиворечиво/правдоподобно присутствовать в оригинальном (исходном) наборе данных.

**Генеративно-состязательные сети (GAN)** — это класс фреймворков глубокого обучения со структурой генеративной модели. Их задача — генерировать новые, сложные (выходные) данные: например, изображения или аудиофайлы, которых до генерации не существовало.

#### Принцип работы GAN

**Генеративно-состязательная сеть** (англ. Generative adversarial network, сокращённо GAN) — алгоритм машинного обучения без учителя, построенный на комбинации из двух нейронных сетей, одна из которых **(сеть G)** генерирует образцы (см. Генеративная модель), а другая **(сеть D)** старается отличить правильные («подлинные») образцы от неправильных (см. Дискриминативная модель). Так как сети G и D имеют противоположные цели — создать образцы и отбраковать образцы — между ними возникает антагонистическая игра.

Принцип состязательности в сети GAN нередко описывается через метафоры. Например, генеративная сеть уподобляется фальшивомонетчику или подделывателю картин, а дискриминативная — эксперту, который стремится распознать подделку.

#### Сравнение с глубоким обучением

Обучение с подкреплением похоже на глубокое обучение, за исключением одного момента: в случае Reinforcement Learning машина обучается методом проб и ошибок, используя данные из собственного опыта.

Алгоритм обучения с подкреплением – это независимая система с самообучением. Чтобы добиться наилучших результатов, машина учится в режиме постоянной практики, из чего следует концепция обучения методом проб и ошибок.

### Сравнение данных реального мира и синтетических данных

| Критерий | Трудности с данными реального мира | Преимущества синтетических данных |
|----------|-----------------------------------|----------------------------------|
| **Приватность** | Данные реального мира, такие как данные пациентов или клиентов, могут быть строго конфиденциальными. Обмен этими данными с другими командами или их использование для обучения моделей ИИ или разработки приложения может нарушать стандарты конфиденциальности или представлять риск раскрытия персонально идентифицируемой информации (PII) и защищенной медицинской информации (PHI). | Синтетические данные гарантируют, что все конфиденциальные данные будут полностью анонимизированы. В сочетании с другими методами повышения приватности, такими как дифференциальная приватность, синтетические данные могу создавать необратимо приватные данные с математическими гарантиями. |
| **Сбор и маркировка** | Собирать реальные данные сложно, долго и дорого, и даже если они собраны, требуется много времени, денег и трудочасов, чтобы обеспечить очистку и маркировку данных для использования в разработке и обучении моделей ИИ. | Используя синтетические данные, организации могут создавать дополнительные маркированные примеры для обучающих наборов за меньшую стоимость, чем при традиционном ручном маркировании. Синтетические данные создаются «по требованию», поэтому новые данные могут генерироваться со скоростью разработки, а их маркировка происходит автоматически. |
| **Соответствие нормативным требованиям** | Растущее государственное регулирование ограничивает использование некоторых реальных данных. Такие нормативные акты, как GDPR, CCPA, HIPAA, Закон ЕС об ИИ и другие, затрудняют использование реальных данных в бизнес-приложениях. | Поскольку синтетические данные основаны на реальных, но не являются таковыми, они, как правило, отличаются от исходных данных. Синтетические данные помогают снизить риски несоблюдения этих норм и одновременно делают данные легкодоступными для инновации. |
| **Предвзятость и разнообразие** | Данные реального мира могут содержать нежелательные погрешности. Такие погрешности, как раса, класс, пол и т. д., приведут к нежелательной предвзятости в последующих приложениях, для которых используются данные. | Синтетические данные позволяют увеличить число недопредставленных классов, чтобы окончательно изменить распределение в наборе данных. Это используется для устранения нежелательной предвзятости и позволяет организациям создавать справедливые, ответственные и репрезентативные приложения. |
| **Полнота данных** | Реальные данные часто оказываются неполными. Из-за ручного ввода данных, игнорирования или проблемных полей, а также из-за переходов системы. | Синтетические модели данных используются для заполнения пробелов в наборах данных контекстно-последовательной информацией. |
| **Объем и поставки** | Многие организации сталкиваются с «Уловкой-22»: им нужны ценные данные для роста, но прежде чем они вырастут ценные данные, необходимо вырастит. | В случае проблемы «холодного старта», когда данных не существует, организации создают синтетические данные с помощью простой инструкции на естественном языке или определения схемы. |
| **Новые или смоделированные условия** | Реальные данные часто не являются широкодоступными для отдаленных пограничных случаев или ситуаций, таких как мошенничество, когда существует лишь ограниченное количество случаев и недостаточно данных для моделирования. | Синтетические модели данных позволяют организациям обучать модели ИИ на отдаленных, маловероятных или гипотетических пограничных случаях путем генерации данных для новых, неизведанных сред. |

### Уровни приложений генеративного ИИ

#### Текст
- Маркетинг (контент)
- Продажи (email)
- Поддержка (чат/email)
- Общее письмо
- Заметки
- Другое

#### Код
- Генерация кода
- Документация кода
- Текст в SQL
- Создатели веб-приложений

#### Изображения
- Генерация изображений
- Потребительские/Соцсети
- Медиа/реклама
- Дизайн

#### Речь
- Синтез голоса

#### Видео
- Монтаж/генерация видео

#### 3D
- 3D модели/сцены

#### Другое
- Игры
- RPA
- Музыка
- Аудио
- Биология и химия

### Процесс генерации синтетических данных

```mermaid
flowchart LR
    subgraph input[" "]
        A[📄<br/>Реальные данные]
    end
    
    subgraph process["Процесс создания синтетических данных"]
        B[📦<br/>Обучение модели]
        C[🎛️<br/>Настройка]
        D[📊<br/>Отчет и уточнение]
        E[➕<br/>Генерация]
    end
    
    subgraph output[" "]
        F[📄<br/>Синтетические данные]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    
    style A fill:#fff,stroke:#000,stroke-width:3px
    style F fill:#fff,stroke:#ff5722,stroke-width:4px
    style process fill:#e0e0e0,stroke:#e0e0e0
    style input fill:#fff,stroke:#fff
    style output fill:#fff,stroke:#fff
    style B fill:#fff,stroke:#666,stroke-width:2px
    style C fill:#fff,stroke:#666,stroke-width:2px
    style D fill:#fff,stroke:#666,stroke-width:2px
    style E fill:#fff,stroke:#666,stroke-width:2px
```

### Как работает копилот (ИИ ассистент)

```mermaid
flowchart LR
    A[🧑<br/>Ввод пользователя]
    B[⚙️<br/>Обработка естественного языка NLP]
    C[🔍<br/>Понимание контекста]
    D[📁<br/>Поиск информации]
    E[💻<br/>Генерация ответов]
    F[💬<br/>Обратная связь с пользователем]
    G[🎯<br/>Непрерывное обучение]
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    
    style A fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style B fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style C fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style D fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style E fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style F fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    style G fill:#2c3e50,stroke:#e74c3c,stroke-width:3px,color:#fff
    
    linkStyle 0,1,2,3,4,5 stroke:#e74c3c,stroke-width:3px
```

### Классификация моделей

**LLM (Large Language Models) – большие модели**
- Формально от 600 млрд. параметров
- Примеры: GPT-4, PaLM, LLaMA-2 70B и выше

**SLM (Small Language Models) – малые модели**
- От 150 до 600 млрд. параметров
- Баланс между производительностью и эффективностью

**MLM (Micro Language Models) – микро модели**
- Менее 150 млрд. параметров
- Компактные модели для устройств с ограниченными ресурсами
- Примеры: модели для мобильных устройств, edge computing

### Контроль отбора проб (сэмплинг в LLM)

**Принцип работы LLM:**

LLM формально не предсказывают одну лексему. Они предсказывают вероятности того, какой может быть следующая лексема, причем каждая лексема в словаре получает свою вероятность. Вероятности этих лексем затем сэмплируются, чтобы определить, какой будет следующая произведенная лексема.

**Ключевые параметры сэмплинга:**

**Temperature (температура)**
- Контролирует случайность и креативность генерации
- **Температура регулирует степень случайности при выборе**
- **Более низкие температуры подходят для подсказок, которые ожидают более детерминированного ответа**, в то время как более высокие температуры могут привести к более разнообразным или неожиданным результатам
- **Температура 0 - жадное декодирование**, детерминированный подход с явно выбранным маркером наибольшей вероятности
- **Температура, близкая к максимальной, как правило, создает больше случайных результатов**. И по мере того как температура становится все выше и выше, все токены становятся одинаково вероятными для того, чтобы стать следующим предсказанным токеном
- Низкая температура (близкая к 0) → более предсказуемые и консервативные ответы
- Высокая температура (близкая к 1 или выше) → более разнообразные и креативные ответы

**top-K**
- Ограничивает выбор K наиболее вероятными токенами
- Например, при top-K=50 модель рассматривает только 50 самых вероятных следующих токенов
- Помогает избежать выбора маловероятных токенов

**top-P (nucleus sampling)**
- Выбирает токены, чья суммарная вероятность достигает порога P
- Например, при top-P=0.9 модель выбирает минимальный набор токенов, суммарная вероятность которых ≥ 90%
- Динамически адаптируется к распределению вероятностей

**Temperature, top-K и top-P** — наиболее распространенные параметры конфигурации, которые определяют, как обрабатываются предсказанные вероятности токенов для выбора одного выходного токена.

#### Top-K vs Top-P настройки моделей

**Top-K и top-P** (также известные как выборка ядра) - это две настройки выборки, используемые в LLM, чтобы ограничить предсказание следующего лексем лексемами с наибольшей предсказанной вероятностью.

**Основные различия:**

**Top-K (фиксированное количество)**
- Всегда выбирает ровно K наиболее вероятных токенов
- Фиксированный размер набора кандидатов
- Не адаптируется к распределению вероятностей
- Пример: при top-K=10 всегда рассматриваются 10 токенов, независимо от их вероятностей
- **Выборка Top-K отбирает K наиболее вероятных лексем из предсказанного моделью распределения**
- **Чем выше top-K**, тем более **творческим и разнообразным** будет вывод модели
- **Чем ниже top-K**, тем более **спокойным и фактическим** будет вывод модели
- **Значение top-K, равное 1, эквивалентно жадному декодированию** (всегда выбирается самый вероятный токен)

**Top-P (динамический порог)**
- Выбирает переменное количество токенов в зависимости от их суммарной вероятности
- Адаптивный размер набора кандидатов
- Более гибкий подход к различным распределениям вероятностей
- Пример: при top-P=0.9 может выбрать 3 токена (если их суммарная вероятность 90%) или 20 токенов (если вероятности более равномерно распределены)
- **Выборка Top-P отбирает лучшие лексемы, чья кумулятивная вероятность не превышает усредненного значения (P)**
- **Значения P варьируются от 0** (жадное декодирование - выбор только самого вероятного токена) **до 1** (все лексемы в словаре LLM доступны для выбора)

**Рекомендации по использованию:**
- Для более предсказуемых результатов → используйте низкие значения temperature и top-K
- Для креативной генерации → используйте высокую temperature и top-P
- Часто top-K и top-P используются вместе для более тонкого контроля

### Раскрытие «черного ящика» (Explainable AI)

**Проблема «черного ящика»:**

Модели ИИ, особенно сети глубокого обучения, часто называют **«черными ящиками»**, потому что их внутренняя работа сложна и трудна для интерпретации.

**Explainable AI (XAI) - Объяснимый ИИ:**

ИИ стремится открыть этот черный ящик, визуализируя, как и почему ИИ принимает решения, такие как выявление признаков, которые привели к классификации объекта.

**Методы визуализации и интерпретации:**

1. **Тепловые карты активации (Heatmaps)**
   - Показывают, какие области входного изображения были наиболее важны для принятия решения
   - Используются методы: Grad-CAM, Saliency Maps, Attention Maps

2. **Feature Visualization (Визуализация признаков)**
   - Показывает, какие паттерны и признаки модель научилась распознавать
   - Помогает понять, на что "смотрит" каждый слой нейронной сети

3. **LIME (Local Interpretable Model-agnostic Explanations)**
   - Создает локальные интерпретируемые модели для объяснения предсказаний

4. **SHAP (SHapley Additive exPlanations)**
   - Показывает вклад каждого признака в итоговое предсказание

**Зачем нужна интерпретируемость:**

- **Доверие**: Пользователи и заинтересованные стороны должны понимать, почему модель приняла то или иное решение
- **Отладка**: Помогает выявить ошибки и предвзятость в модели
- **Соответствие требованиям**: Во многих отраслях (медицина, финансы, юриспруденция) требуется объяснять решения ИИ
- **Улучшение модели**: Понимание работы модели помогает её совершенствовать

**Пример:** При классификации изображения птицы, модель может визуализировать, что решение было принято на основе формы клюва, окраса перьев и формы головы, показывая эти области на тепловой карте активации.

<img src="./images/bb.png">

#### Важность функций и приоритетные области

Методы ИИ могут выделять, на каких частях изображения сфокусировалась модель ИИ для принятия решения. Например, он может выделять крылья, клюв или узоры оперения птицы, давая представление о том, что модель «заметила», определяя, что объект действительно является птицей.

**Практическое применение:**
- **Медицинская диагностика**: Показывает, какие области рентгеновского снимка или МРТ привели к диагнозу
- **Автономные автомобили**: Визуализирует, на какие объекты (пешеходы, знаки, другие автомобили) обратила внимание система
- **Контроль качества**: Выделяет дефекты или области интереса на производственных изделиях
- **Распознавание лиц**: Показывает, какие черты лица были ключевыми для идентификации

### Практические Рекомендации

#### Пошаговый подход к сложным задачам

Для сложных задач разбейте подсказку на более мелкие, управляемые шаги:

1. **Разбивка на компоненты**: Такой подход гарантирует, что каждая часть задачи будет тщательно проработана и может повысить точность конечного ответа.

2. **Планирование**: Например, если вы работаете над комплексным проектом, вы можете начать с того, чтобы попросить GPT составить план или ключевые идеи.

3. **Итеративная разработка**: Как только они будут добавлены, следуйте подсказкам, чтобы расширить каждый раздел по отдельности.

4. **Преимущества метода**: Этот пошаговый подход позволяет искусственному интеллекту предоставить более целенаправленные ответы, а вам — направлять его на протяжении всего пути, уточняя и развивая каждый ответ.

#### Использование контекста и данных

При необходимости укажите соответствующий контекст и данные в запросе. ИИ работает лучше, когда у него есть необходимая база, поэтому кратко опишите любой необходимый контекст для вашего запроса.

Например, запрос может включать дополнительный контекст или прикреплять связанную информацию, такую как PDF-файл или набор данных, что позволяет GPT анализировать или ссылаться на определенные детали.

**Пример улучшения запроса:**

Вместо того, чтобы спрашивать: «Обобщите глобальные тенденции», более эффективным вопросом с учетом контекста было бы следующее: «Используя прилагаемый отчет, предоставьте краткое изложение текущих глобальных экономических тенденций с акцентом на развивающиеся страны».

#### Рефлексивные запросы для глубокого анализа

Попросите ИИ «отразить» или «рассмотреть» различные аспекты, если вы ищете вдумчивый ответ.

Такие формулировки, как «рассмотреть разные точки зрения» или «предоставить анализ», помогают смоделировать более глубокие рассуждения. Например, пользователь может работать над предложением клиента. Он поручает GPT пошагово рассчитать затраты, учесть скидки и объяснить добавленную стоимость тех или иных элементов пакета. Этот метод эффективен для задач, связанных с несколькими факторами или решениями.

**Результат:**

Поощряя модель «обдумывать» каждый аспект перед ответом, можно получить более полный и логически структурированный ответ, особенно для задач, включающих сценарии, расчеты или стратегические рекомендации.

#### Использование ролевой модели и промптов от GPT

Настройте ответы GPT, создав «пользовательский GPT», настроив запрос в качестве определенной роли (например, «действовать как аналитик данных» или «притворяться, что вы менеджер по продукту»).

Такой подход заставляет ИИ адаптировать свой тон и реакцию в соответствии со специализированными потребностями.

**Интерактивные вопросы от модели:**

Попросите GPT задать вопросы, например, «Что бы ты посоветовала уточнить еще?», «Какие вопросы ты бы задала себе сейчас?»

### Понятие ИИ агента

**ИИ-агент** — структура, которая автономно собирает данные и выполняет задачи с использованием этих данных. Агент может действовать независимо или от имени другой системы или человека. Эти агенты могут выполнять различные функции, такие как:

- Принятие решений
- Решение проблем
- Взаимодействие с внешней средой
- Выполнение действий

По сути, агент выполняет задачи самостоятельно для достижения поставленных целей.

### Доверие и подотчетность

Объяснение решения ИИ помогает укрепить доверие к системам ИИ, показывая, что они не просто выдают случайные результаты, а вместо этого основаны на различимых закономерностях и логических структурах. Это имеет решающее значение для отраслей, где понимание принятия решений с помощью ИИ может повлиять на справедливость, предвзятость и подотчетность.

### Типы и точность языковых моделей

**LLM** (модели больших данных, свыше 600 млрд записей обучения) – модели общего назначения

**SLM** (модели малых данных, 50-500 млрд. записей обучения) – сфокусированы на определенной области

**MLM** (модели микро данных, менее 30-50 млрд записей) – как правило, корпоративные, максимально погружены в контекст

### Примеры GAN

- ChatGPT
- YandexGPT
- GigaChat
- Kandinsky
- Gemini
- Perplexity
- DeepSeek

### Примеры алгоритмов/библиотек

**State-Action-Reward-State-Action (SARSA).** Этот алгоритм обучения с подкреплением начинается с предоставления агенту такого коэффициента, как политика (on-policy). В данном случае политика – это вероятность, с помощью которой алгоритм оценивает шансы определенных действий, приводящих к вознаграждениям или положительным состояниям.

**Q-Learning.** В этом подходе к Reinforcement Learning используется противоположный подход. Агент не получает политики (on-policy), соответственно, его исследование окружающей среды является более самостоятельным. В Q-learning у нас нет ограничений на выбор действия (action) для алгоритма. Он полагает, что все последующие выборы actions будут оптимальными по умолчанию, поэтому алгоритм производит операцию выбора исходя из максимизации оценки Q.

**Deep Q-Networks (Глубокие Q-сети).** Этот алгоритм использует нейронные сети в дополнение к методам обучения с подкреплением (reinforcement learning). Нейросети осуществляют самостоятельное исследование (research) среды обучения с подкреплением для выбора наиболее оптимального значения. То, как алгоритм будет себя вести и подбирать значения, основано на выборке прошлых положительных действий, полученных нейронной сетью.

**LLM – Large Language models (Модели больших языков)** – Copilot, Gemini, YaGPT, GigaChat (Сбер), Perplexity

### Три варианта выбора и адаптации модели GenAI для организации

При внедрении GenAI-решений в организацию существует три основных подхода:

| Критерий | Вариант 1: Общедоступная модель общего назначения | Вариант 2: Специализированное корпоративное SaaS ИИ-решение | Вариант 3: Защищенная облачная LLM |
|----------|--------------------------------------------------|-------------------------------------------------------------|-----------------------------------|
| **Примеры** | ChatGPT, GPT, Claude, Gemini | Salesforce Einstein, Microsoft Dynamics 365 AI, отраслевые решения | Azure OpenAI, AWS Bedrock, Google Cloud Vertex AI, приватные развертывания |
| **Скорость внедрения** | ✅ Очень быстро (минуты) | ⚡ Средне (недели-месяцы) | ⏱️ Долго (месяцы) |
| **Стоимость** | 💰 Низкая | 💰💰 Средняя-высокая | 💰💰💰 Высокая |
| **Контроль данных** | ❌ Минимальный | ⚠️ Ограниченный | ✅ Полный |
| **Кастомизация** | ❌ Отсутствует | ⚠️ Ограниченная | ✅ Максимальная |
| **Специализация** | ❌ Общего назначения | ✅ Под отрасль | ✅ Настраивается под бизнес |
| **Требования к компетенциям** | 👤 Минимальные | 👤👤 Средние | 👤👤👤 Высокие |
| **Безопасность** | ⚠️ Стандартная | ✅ Корпоративная | ✅✅ Максимальная |
| **Техподдержка** | 📧 Стандартная | ✅ Вендор | 🔧 Собственная команда |
| **Интеграция** | ⚠️ Через API | ✅ Нативная с корпоративными системами | ✅ Гибкая |
| **Масштабируемость** | ✅ Автоматическая | ⚠️ Зависит от тарифа | ✅ Настраиваемая |
| **Обновления** | ✅ Автоматические от провайдера | ✅ От вендора | 🔧 Управляемые самостоятельно |

### Преимущества и недостатки

#### Вариант 1: Общедоступная модель
**✅ Преимущества:**
- Быстрый старт без необходимости настройки
- Широкий спектр возможностей
- Регулярные обновления и улучшения
- Низкий порог входа

**❌ Недостатки:**
- Отсутствие специализации
- Ограниченный контроль над данными
- Зависимость от внешнего провайдера
- Возможные проблемы с конфиденциальностью

#### Вариант 2: Корпоративное SaaS решение
**✅ Преимущества:**
- Готовое решение под отрасль
- Интеграция с корпоративными системами
- Техническая поддержка от вендора
- Соответствие отраслевым стандартам

**❌ Недостатки:**
- Высокая стоимость лицензий
- Ограниченная кастомизация
- Зависимость от вендора
- Возможные ограничения масштабируемости

#### Вариант 3: Защищенная облачная LLM
**✅ Преимущества:**
- Полный контроль над данными и моделью
- Тонкая настройка (fine-tuning) под бизнес
- Соответствие требованиям безопасности
- Гибкость в выборе инфраструктуры

**❌ Недостатки:**
- Требуются высокие технические компетенции
- Необходимость в инфраструктуре и DevOps
- Высокие первоначальные инвестиции
- Ответственность за обслуживание

### Критерии выбора подхода

При выборе подходящего варианта следует учитывать:

1. **Требования к безопасности и конфиденциальности данных**
2. **Бюджет и ресурсы** (финансовые и человеческие)
3. **Уровень технической зрелости организации**
4. **Специфику бизнес-задач** (общие vs. узкоспециализированные)
5. **Скорость внедрения** (быстрый пилот vs. долгосрочная стратегия)
6. **Требования к кастомизации**
7. **Объемы обрабатываемых данных**
8. **Требования к интеграции** с существующими системами

## [Модуль 6] Графы. Построение маршрута. Прогноз поведения пользователя

### Определение графа

**Графом G(V,E) называется пара множеств, где:**

- **V** – совокупность объектов, а
- **E** – совокупность пар отношений между этими объектами

**Примеры графов:**

#### 1. Ориентированный граф с взвешенными ребрами

```mermaid
graph LR
    A -->|4| B
    A -->|2| C
    B -->|5| C
    B -->|10| D
    C -->|3| E
    E -->|4| D
    D -->|11| F
```

#### 2. Неориентированный граф

```mermaid
graph LR
    1 --- 2
    1 --- 5
    2 --- 3
    2 --- 5
    3 --- 4
    3 --- 6
    4 --- 5
    4 --- 6
```

#### 3. Дерево (иерархическая структура)

```mermaid
graph TD
    v1[v₁] --> v3[v₃]
    v1 --> v2[v₂]
    v2 --> v4[v₄]
    v2 --> v5[v₅]
    v3 --> v8[v₈]
    
    v4 --> v9[v₉]
```

### Задача поиска оптимального маршрута

#### Алгоритм Дейкстры

Алгоритм Дейкстры (Dijkstra's algorithm) — это алгоритм для нахождения кратчайших путей от одной из вершин графа до всех остальных. Работает только для графов с неотрицательными весами рёбер.

**Пример графа для алгоритма Дейкстры:**

```mermaid
graph LR
    A -->|4| B
    A -->|3| C
    A -->|7| E
    B -->|5| D
    B -->|6| C
    C -->|11| D
    C -->|8| E
    D -->|2| E
    D -->|2| F
    D -->|10| G
    E -->|5| G
    F -->|3| G
```

**Основные шаги алгоритма:**

1. **Инициализация**: 
   - Расстояние до начальной вершины = 0
   - Расстояние до всех остальных вершин = ∞
   - Все вершины помечаются как непосещённые

2. **Итерация**:
   - Выбирается непосещённая вершина с минимальным расстоянием
   - Для всех её соседей вычисляется новое расстояние
   - Если новое расстояние меньше текущего — обновляем его
   - Вершина помечается как посещённая

3. **Завершение**: 
   - Алгоритм завершается, когда все вершины посещены
   - Результат — кратчайшие расстояния от начальной вершины до всех остальных

**Сложность алгоритма:**
- С использованием простого массива: O(V²)
- С использованием бинарной кучи: O((V + E) log V)
- С использованием фибоначчиевой кучи: O(E + V log V)

где V — количество вершин, E — количество рёбер.

### Задачи классификации данных в социальных сетях

Основные направления применения графов в анализе социальных сетей:

1. **Отбор признаков пользователя** — анализ профиля и паттернов поведения
2. **Прогнозируемое поведение (CJ)** — предсказание действий и churn prediction
3. **Социальный граф** — анализ связей и влиятельных узлов
4. **Определение эмоционального настроя** — sentiment analysis
5. **Поиск и анализ сообществ** — community detection
6. **Анализ спама** — обнаружение ботов и фейковых профилей

### Задачи построения социального графа и поиска сообществ

**Основные задачи:**

1. **Выявить взаимосвязи (общие компоненты)**
   - Построение графа связей между пользователями
   - Определение компонент связности
   - Анализ силы связей между узлами
   - Выявление ключевых связующих узлов

2. **Определить сообщества (группы, каналы и т.п.), отвечающие заданным показателям**
   - Кластеризация пользователей в сообщества
   - Оценка качества сообществ (модулярность)
   - Выделение тематических групп
   - Анализ структуры и характеристик сообществ

**Визуализация социального графа:**

```mermaid
graph LR
    subgraph Community1["Сообщество 1"]
        A1((•)) --- A2((•))
        A2 --- A3((•))
        A3 --- A1
    end
    
    subgraph Community2["Сообщество 2"]
        B1((•)) --- B2((•))
        B2 --- B3((•))
    end
    
    subgraph Community3["Сообщество 3"]
        C1((•)) --- C2((•))
        C2 --- C3((•))
        C3 --- C4((•))
    end
    
    A3 -.-> B1
    B3 -.-> C1
```

*Примечание: Граф демонстрирует выделение различных сообществ с плотными связями внутри и более слабыми связями между сообществами.*

### Задача исследования качества контента

При анализе качества контента в социальных сетях используются следующие ключевые метрики:

1. **Среднее число сообщений в день** — активность пользователя/сообщества
2. **Число ответов** — уровень вовлеченности аудитории
3. **Число повторных публикаций (репостов)** — виральность контента
4. **Ссылки на сторонний контент** — характер и происхождение публикуемой информации

Эти показатели позволяют оценить:
- Качество и релевантность контента
- Уровень взаимодействия с аудиторией
- Активность и вовлеченность пользователей
- Распространение информации в сети

### Найти путь к своему клиенту

**Решаемые задачи:**

1. **Определить признаки, по которым формировать предложение**
   - Анализ характеристик целевой аудитории
   - Сегментация пользователей по интересам и поведению
   - Выявление ключевых потребностей и предпочтений

2. **Найти путь, как «добраться» до своего клиента**
   - Построение карты сообществ и связей между ними
   - Определение кратчайших путей распространения информации
   - Поиск ключевых узлов (influencers) для охвата целевой аудитории
   - Анализ мостов между различными сегментами

**Визуализация сегментов аудитории:**

```mermaid
graph TD
    subgraph Tech["IT и технологии"]
        T1((•)) --- T2((•))
        T2 --- T3((•))
        T3 --- T4((•))
    end
    
    subgraph Business["Предприниматели"]
        B1((•)) --- B2((•))
        B2 --- B3((•))
    end
    
    subgraph Fitness["Спортсмены"]
        F1((•)) --- F2((•))
        F2 --- F3((•))
    end
    
    subgraph Students["Студенты"]
        S1((•)) --- S2((•))
    end
    
    T3 -.-> B1
    B2 -.-> F1
    F2 -.-> S1
```

**Пример:** [Анализ социальных связей для таргетирования](https://habr.com/ru/company/dca/blog/265077/)

### Социальный граф

**Определение:**

СГ (социальный граф) — граф, узлы которого представлены социальными объектами, такими как пользовательские профили с различными атрибутами (например: имя, день рождения, родной город), сообщества, медиаконтента и т.п., а ребра — социальными связями между ними.

**Метрики социального графа:**

1. **Гомофилия** — степень связей объекта с себе подобными
2. **Сплоченность** — степень связанности пользователей в сообществе
3. **Центральность** — степень влияния пользователя в группе (по числу связей)
4. **Взаимность** — друг моего друга – мой друг?
5. **Множественность** — число множественных связей, например, ВУЗ и работа
6. **Мост** — объект, являющийся связью между кластерами
7. **Расстояние** — минимальное количество связей, требуемых для установления наличия взаимосвязи между двумя отдельными пользователями

**Максимальная связность графа:**

Максимальное число связей в графе вычисляется по формуле:

$$
\text{MAX (Связность)} = \frac{N \times (N-1)}{2}
$$

где N — число узлов в графе.

**Пример расчета метрик:**

```mermaid
graph TD
    U0((•))
    U1((1))
    U2((2))
    U3((3))
    U4((4))
    U5((5))
    U6((6))
    
    U0 --- U3
    U1 --- U2
    U1 --- U6
    U1 --- U4
    U2 --- U3
    U2 --- U4
    U2 --- U5
    U2 --- U6
    U3 --- U4
    U4 --- U5
```

Для графа с 6 узлами:
- **Max = N×(N-1)/2 = 6×5/2 = 15** — максимальное количество возможных связей
- **Фактическое количество связей = 10**
- **Сплоченность = 10/15 ≈ 0.67** — фактическая плотность связей

**Центральность узлов (количество связей):**
- Узел 2: 4/4 (самый центральный)
- Узел 1: 3/4
- Узел 3: 3/4  
- Узел 4: 4/4
- Узел 5: 2/2
- Узел 6: 2/4

### Стохастические графы (вероятностный анализ)

**Определение:**

Стохастический граф — это ориентированный граф, ребра которого имеют вероятности переходов между узлами. Используется для моделирования случайных процессов и предсказания поведения в системах с неопределенностью.

**Пример стохастического графа:**

```mermaid
graph LR
    S1((S1))
    S2((S2))
    S3((S3))
    S4((S4))
    End1[Конец 1]
    End2[Конец 2]
    
    S1 -->|P| S2
    S1 -->|P| S3
    S2 -->|P| S1
    S2 -->|P| End1
    S3 -->|P| S4
    S4 -->|P| End2
    
    style End1 stroke-dasharray: 5 5
    style End2 stroke-dasharray: 5 5
```

*Примечание: P обозначает вероятность перехода между состояниями, пунктирные узлы — конечные состояния.*

**Области применения:**

- **Продажа билетов на транспорт** — прогнозирование маршрутов пассажиров и оптимизация расписания
- **Газовые потоки (металлургия)** — моделирование распределения газов в технологических процессах
- **Анализ социальных сетей (переход по публикациям)** — предсказание пути пользователя по контенту, Customer Journey


